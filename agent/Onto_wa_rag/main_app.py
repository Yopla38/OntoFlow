"""
    ------------------------------------------
    Copyright: CEA Grenoble
    Auteur: Yoann CURE
    EntitÃ©: IRIG
    AnnÃ©e: 2025
    Description: Agent IA d'IntÃ©gration Continue
    ------------------------------------------
    """

# onto_rag.py
import os
import hashlib
import json
import logging
import shutil
import uuid
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime
import asyncio

from .CONSTANT import API_KEY_PATH, CHUNK_SIZE, CHUNK_OVERLAP, ONTOLOGY_PATH_TTL, MAX_CONCURRENT, MAX_RESULTS, \
    STORAGE_DIR, FORTRAN_AGENT_NB_STEP
from .context_provider.query_router import IntelligentQueryRouter
from .fortran_analysis.providers.Fortran_agent import FortranAgent
from .fortran_analysis.providers.consult import FortranEntityExplorer
from .ontology.classifier import OntologyClassifier
from .ontology.ontology_manager import OntologyManager
from .semantic_analysis.core.semantic_chunker import LevelBasedSearchEngine, ConceptualHierarchicalEngine
from .utils.document_processor import DocumentProcessor

# Imports pour le RAG
from .utils.rag_engine import RAGEngine
from .provider.llm_providers import OpenAIProvider
from .provider.get_key import get_openai_key


class OntoDocumentProcessor(DocumentProcessor):
    """
    Processeur de documents personnalisÃ© qui utilise les chunkers appropriÃ©s
    selon le type de fichier et bypass le MarkdownConverter pour certains types
    """

    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200, file_extensions: dict = None):
        super().__init__(chunk_size, chunk_overlap, use_semantic_chunking=True)
        self.file_extensions = file_extensions or {}

        # Initialiser les chunkers spÃ©cialisÃ©s
        self.fortran_processor = None  # Sera initialisÃ© plus tard

        from semantic_analysis.core.semantic_chunker import HierarchicalSemanticChunker
        self.hierarchical_chunker = HierarchicalSemanticChunker(
            min_chunk_size=200,
            max_chunk_size=chunk_size,
            overlap_sentences=2,
            ontology_manager=None,
            concept_classifier=None
        )

        self.ontology_manager = None


        # Types de fichiers qui doivent Ãªtre lus directement (sans conversion)
        self.direct_read_types = {'fortran', 'code', 'text', 'config'}

    def set_ontology_components(self, ontology_manager, concept_classifier):
        """Configure les composants ontologiques"""
        self.ontology_manager = ontology_manager

        # CORRECTION : Configurer le chunker hiÃ©rarchique
        self.hierarchical_chunker.set_ontology_components(ontology_manager, concept_classifier)

        # Configurer aussi l'ancien chunker pour compatibilitÃ©
        if hasattr(self, 'semantic_chunker') and self.semantic_chunker:
            self.semantic_chunker.set_ontology_manager(ontology_manager, concept_classifier)

        print("âœ… Composants ontologiques configurÃ©s dans le processeur")

    async def initialize_fortran_module(self, document_store, rag_engine=None):
        """
        Initialise le module Fortran aprÃ¨s que document_store soit disponible.
        """
        from fortran_analysis.integration.document_processor_integration import get_fortran_processor

        # CORRECTION: Attendre que document_store soit prÃªt
        if hasattr(document_store, 'initialize'):
            await document_store.initialize()

        self.fortran_processor = await get_fortran_processor(
            document_store, rag_engine, self.ontology_manager
        )
        print("âœ… Module Fortran initialisÃ©")


    async def _extract_text_with_metadata(self, filepath: str) -> Tuple[str, Dict[str, Any]]:
        """
        Extrait le texte et les mÃ©tadonnÃ©es d'un document
        Override pour gÃ©rer les fichiers non supportÃ©s par MarkdownConverter
        """
        # DÃ©terminer le type de fichier
        extension = Path(filepath).suffix.lower()
        file_type = self.file_extensions.get(extension, 'text')

        # MÃ©tadonnÃ©es de base
        metadata = {
            'file_size': os.path.getsize(filepath),
            'file_type': file_type,
            'modification_date': datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat(),
            'extraction_date': datetime.now().isoformat(),
        }

        # Si c'est un type de fichier qui doit Ãªtre lu directement
        if file_type in self.direct_read_types:
            print(f"ðŸ“– Lecture directe du fichier {file_type}: {Path(filepath).name}")
            try:
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                return content, metadata
            except Exception as e:
                print(f"âŒ Erreur lors de la lecture de {filepath}: {e}")
                raise

        else:
            # Utiliser le convertisseur par dÃ©faut pour les autres types
            print(f"ðŸ”„ Conversion via MarkdownConverter: {Path(filepath).name}")
            return await super()._extract_text_with_metadata(filepath)

    async def process_document(self, filepath: str, document_id: str = None, additional_metadata: dict = None):
        """
        Traite un document en utilisant le chunker appropriÃ© selon son type
        """
        # Si pas d'ID fourni, en gÃ©nÃ©rer un
        if document_id is None:
            document_id = str(uuid.uuid4())

        # DÃ©terminer le type de fichier
        extension = Path(filepath).suffix.lower()
        file_type = self.file_extensions.get(extension, 'text')

        print(f"ðŸ” Type de fichier dÃ©tectÃ©: {file_type} pour {Path(filepath).name}")

        # Extraire le texte et les mÃ©tadonnÃ©es (utilise notre mÃ©thode override)
        text_content, doc_metadata = await self._extract_text_with_metadata(filepath)

        # Fusionner les mÃ©tadonnÃ©es
        metadata = {**doc_metadata, **(additional_metadata or {})}
        # === Notebook Handler (NEW) ===
        if file_type == 'notebook':
            print(f"âœ‚ï¸  Utilisation du retriever spÃ©cialisÃ© pour notebooks: {Path(filepath).name}")
            from OntoFlow.agent.Onto_wa_rag.retriever_adapter import SimpleRetriever
            retriever = SimpleRetriever()
            retriever.build_index_from_notebook(str(filepath))

        # Convertir les chunks du retriever dans le format OntoRAG
            chunks = []
            for i, c in enumerate(retriever.chunks):
                chunks.append({
                    "id": f"{document_id}_chunk_{i}",
                    "content": c["content"],
                    "metadata": {**metadata, "tokens": c["tokens"], "source": str(filepath)}
                      })


        # Utiliser le chunker appropriÃ© selon le type de fichier
        elif file_type == 'fortran':
            print(f"âœ‚ï¸  Utilisation du chunker Fortran sÃ©mantique")

            if not self.fortran_processor:
                raise RuntimeError("Module Fortran non initialisÃ©. Appelez initialize_fortran_module() d'abord.")

            chunks = await self.fortran_processor.process_fortran_document(
                filepath, document_id, text_content, metadata
            )


        elif file_type in ['text', 'markdown']:
            print(f"âœ‚ï¸  Utilisation du chunker sÃ©mantique pour texte")
            chunks = await self.hierarchical_chunker.create_semantic_chunks(
                text_content, document_id, filepath, metadata
            )


        else:
            print(f"âœ‚ï¸  Utilisation du chunker gÃ©nÃ©rique")
            # Utiliser le chunker par dÃ©faut pour les autres types
            chunks = self._create_chunks(text_content, document_id, filepath)
            # Ajouter les mÃ©tadonnÃ©es Ã  chaque chunk
            for chunk in chunks:
                chunk['metadata'].update(metadata)


        print(f"âœ‚ï¸  {len(chunks)} chunks crÃ©Ã©s pour {Path(filepath).name}")

        return document_id, chunks


class OntoRAG:
    """
    RAG optimisÃ© pour les grands ensembles de code avec reconnaissance automatique
    des types de fichiers et chunking sÃ©mantique adaptÃ©.
    """

    def __init__(
            self,
            storage_dir: str = "ontorag_storage",
            api_key_path: str = API_KEY_PATH,
            model: str = "gpt-4o",
            chunk_size: int = CHUNK_SIZE,
            chunk_overlap: int = CHUNK_OVERLAP,
            ontology_path: Optional[str] = None
    ):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)

        self.api_key_path = api_key_path
        self.model = model
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

        # MÃ©tadonnÃ©es des documents
        self.metadata_file = self.storage_dir / "documents_metadata.json"
        self.documents_metadata = self._load_metadata()

        # Extensions supportÃ©es
        self.file_extensions = {
            # Code Fortran
            '.f90': 'fortran', '.f95': 'fortran', '.f03': 'fortran',
            '.f08': 'fortran', '.f': 'fortran', '.for': 'fortran', '.ftn': 'fortran',

            # Documentation
            '.md': 'markdown', '.rst': 'text', '.txt': 'text',

            # PDFs et documents (seront convertis)
            '.pdf': 'pdf', '.doc': 'document', '.docx': 'document',

            # Code source autres
            '.py': 'code', '.c': 'code', '.cpp': 'code',
            '.h': 'code', '.hpp': 'code', '.java': 'code',

            # Configs
            '.yaml': 'config', '.yml': 'config', '.json': 'config',
            '.xml': 'config', '.ini': 'config', '.ipynb': 'notebook'

        }

        # RAG Engine sera initialisÃ© de maniÃ¨re asynchrone
        self.rag_engine = None
        self.logger = logging.getLogger(__name__)

        # Ontologie
        self.ontology_path = ontology_path
        self.ontology_manager = None
        self.classifier = None

        # NOUVEAU : SystÃ¨me de contexte
        self.context_provider = None
        # Agent pour la recherche
        self.agent_fortran = None

    async def initialize(self):
        """Initialise le systÃ¨me RAG de maniÃ¨re asynchrone"""
        if self.rag_engine is not None:
            return

        print("ðŸš€ Initialisation d'OntoRAG...")

        # Initialiser les providers
        openai_key = get_openai_key(api_key_path=self.api_key_path)
        llm_provider = OpenAIProvider(model=self.model, api_key=openai_key)

        # CrÃ©er notre processeur personnalisÃ© AVANT l'initialisation
        self.custom_processor = OntoDocumentProcessor(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            file_extensions=self.file_extensions
        )

        if self.ontology_path and os.path.exists(self.ontology_path):
            print(f"ðŸ“š Chargement de l'ontologie: {os.path.basename(self.ontology_path)}")

            # Initialiser l'OntologyManager
            onto_storage_dir = str(self.storage_dir / "ontology")
            self.ontology_manager = OntologyManager(storage_dir=onto_storage_dir)

            # Charger l'ontologie TTL
            success = self.ontology_manager.load_ontology(self.ontology_path)
            if not success:
                print("âš ï¸ Ã‰chec du chargement de l'ontologie")
            else:
                print(
                    f"âœ… Ontologie chargÃ©e: {len(self.ontology_manager.concepts)} concepts, {len(self.ontology_manager.relations)} relations")

                # Initialiser le classifieur ontologique
                classifier_dir = str(self.storage_dir / "classifier")
                self.classifier = OntologyClassifier(
                    rag_engine=None,  # â† Sera assignÃ© aprÃ¨s
                    ontology_manager=self.ontology_manager,
                    storage_dir=classifier_dir,
                    use_hierarchical=False,
                    enable_concept_classification=True,
                    enable_relation_learning=False,
                    multiscale_mode=False
                )
        else:
            print(f"âš ï¸ Ã‰chec du chargement de l'ontologie, le fichier {self.ontology_path} n'existe pas")

        # Initialiser le RAG Engine
        self.rag_engine = RAGEngine(
            llm_provider=llm_provider,
            embedding_provider=llm_provider,
            storage_dir=str(self.storage_dir / "rag_storage"),
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap
        )

        # IMPORTANT : Assigner le rag_engine au classifier AVANT l'initialisation
        if self.classifier:
            self.classifier.rag_engine = self.rag_engine
            # Assigner aussi au concept_classifier
            if hasattr(self.classifier, 'concept_classifier') and self.classifier.concept_classifier:
                self.classifier.concept_classifier.rag_engine = self.rag_engine
                print("âœ… RAG engine assignÃ© au concept_classifier")
                if hasattr(self.classifier.concept_classifier, 'classify_embedding_direct'):
                    print("âœ… classify_embedding_direct disponible")
            # Assigner au classifier hierarchique/simple
            if hasattr(self.classifier, 'classifier') and self.classifier.classifier:
                self.classifier.classifier.rag_engine = self.rag_engine
                print("âœ… RAG engine assignÃ© au classifier hiÃ©rarchique")

            await self.classifier.initialize()
            print("âœ… Classifieur ontologique initialisÃ©")

        # Assigner le processeur au RAG Engine
        self.rag_engine.processor = self.custom_processor
        self.rag_engine.document_store.processor = self.custom_processor

        await self.rag_engine.initialize()

        # MAINTENANT initialiser le classifier avec le rag_engine disponible
        if self.classifier:
            await self.classifier.initialize()
            print("âœ… Classifieur ontologique initialisÃ©")

            # Lier le classifier Ã  l'ontology_manager
            self.ontology_manager.classifier = self.classifier
            print("âœ… Classifier liÃ© Ã  l'ontology_manager")

            if self.ontology_manager:
                self.ontology_manager.rag_engine = self.rag_engine
                print("âœ… RAG engine liÃ© Ã  l'ontology_manager")

            self.custom_processor.set_ontology_components(self.ontology_manager, self.classifier)

            # â† ASSIGNMENT ICI - aprÃ¨s que tout soit initialisÃ©
            self.custom_processor.ontology_manager = self.ontology_manager
            print("âœ… Ontology_manager assignÃ© au processeur")

        # Initialiser le systÃ¨me de contexte
        await self.custom_processor.initialize_fortran_module(self.rag_engine.document_store, self.rag_engine)

        # Moteur de recherche par niveau
        self.level_search_engine = LevelBasedSearchEngine(
            self.rag_engine.document_store,
            self.rag_engine.embedding_manager.provider
        )

        self.entity_explorer = FortranEntityExplorer(self.custom_processor.fortran_processor.entity_manager, self.ontology_manager)
        self.router = IntelligentQueryRouter(self.rag_engine.llm_provider, self.entity_explorer)

        #  Nous pouvons changer le provider pour l'agent si necessaire
        self.agent_fortran = FortranAgent(llm_provider=self.rag_engine.llm_provider, explorer=self.entity_explorer, max_steps=FORTRAN_AGENT_NB_STEP)

        print("âœ… OntoRAG initialisÃ© avec succÃ¨s!")


    def scan_directory(
            self,
            directory_path: str,
            file_filters: List[str] = None,
            recursive: bool = True,
            exclude_patterns: List[str] = None,
            project_name: str = None,
            version: str = "1.0"
    ) -> List[Dict[str, Any]]:
        """
        Scanne un rÃ©pertoire et retourne la liste des fichiers Ã  traiter

        Args:
            directory_path: Chemin du rÃ©pertoire Ã  scanner
            file_filters: Extensions Ã  inclure (ex: ['f90', 'md', 'txt'])
            recursive: Si True, scan rÃ©cursif des sous-rÃ©pertoires
            exclude_patterns: Patterns Ã  exclure (ex: ['.git', '__pycache__', '.pyc'])
            project_name: Nom du projet (auto-dÃ©tectÃ© si None)
            version: Version du projet

        Returns:
            Liste de dictionnaires compatibles avec add_documents_batch
        """

        directory_path = Path(directory_path).resolve()

        if not directory_path.exists():
            print(f"âŒ RÃ©pertoire non trouvÃ© : {directory_path}")
            return []

        if not directory_path.is_dir():
            print(f"âŒ Le chemin n'est pas un rÃ©pertoire : {directory_path}")
            return []

        # Filtres par dÃ©faut
        if file_filters is None:
            file_filters = ['f90', 'f95', 'f03', 'f08', 'f', 'for', 'ftn',  # Fortran
                            'md', 'rst', 'txt',  # Documentation
                            'py', 'c', 'cpp', 'h', 'hpp',  # Autres codes
                            'yaml', 'yml', 'json', 'xml']  # Configs

        # Exclusions par dÃ©faut
        if exclude_patterns is None:
            exclude_patterns = [
                '.git', '.svn', '.hg',  # ContrÃ´le de version
                '__pycache__', '.pytest_cache', 'node_modules',  # Cache
                '.vscode', '.idea', '.DS_Store',  # IDE/SystÃ¨me
                'build', 'dist', 'target', 'out',  # Build
                '.pyc', '.pyo', '.pyd', '.so', '.dll',  # Binaires
                'CMakeFiles', 'CMakeCache.txt'  # CMake
            ]

        # Auto-dÃ©tecter le nom du projet si pas fourni
        if project_name is None:
            project_name = directory_path.name

        print(f"ðŸ“ Scan du rÃ©pertoire : {directory_path}")
        print(f"   Filtres : {file_filters}")
        print(f"   RÃ©cursif : {recursive}")
        print(f"   Projet : {project_name}")

        found_files = []

        # Fonction de scan
        def scan_folder(folder_path: Path, current_depth: int = 0):
            try:
                for item in folder_path.iterdir():

                    # VÃ©rifier les exclusions
                    if any(pattern in str(item) for pattern in exclude_patterns):
                        continue

                    if item.is_file():
                        # VÃ©rifier l'extension
                        extension = item.suffix.lower().lstrip('.')
                        if extension in file_filters:
                            # Calculer le chemin relatif pour les mÃ©tadonnÃ©es
                            relative_path = item.relative_to(directory_path)

                            file_info = {
                                "filepath": str(item),
                                "project_name": project_name,
                                "version": version,
                                "additional_metadata": {
                                    "relative_path": str(relative_path),
                                    "directory_depth": current_depth,
                                    "parent_directory": str(item.parent.name),
                                    "scanned_from": str(directory_path),
                                    "file_size": item.stat().st_size,
                                    "scan_method": "directory_scan"
                                }
                            }
                            found_files.append(file_info)

                    elif item.is_dir() and recursive:
                        # Scan rÃ©cursif des sous-rÃ©pertoires
                        scan_folder(item, current_depth + 1)

            except PermissionError:
                print(f"âš ï¸ AccÃ¨s refusÃ© : {folder_path}")
            except Exception as e:
                print(f"âš ï¸ Erreur scan {folder_path} : {e}")

        # Lancer le scan
        scan_folder(directory_path)

        # Statistiques
        file_stats = {}
        for file_info in found_files:
            ext = Path(file_info["filepath"]).suffix.lower().lstrip('.')
            file_stats[ext] = file_stats.get(ext, 0) + 1

        print(f"âœ… Scan terminÃ© : {len(found_files)} fichiers trouvÃ©s")
        for ext, count in sorted(file_stats.items()):
            print(f"   .{ext}: {count} fichiers")

        return found_files

    async def generate_global_summary(self, scope: str = 'all') -> Dict[str, Any]:
        """GÃ©nÃ¨re un rÃ©sumÃ© global de tous les documents"""

        if not await self._ensure_initialized():
            return {"error": "RAG non initialisÃ©"}

        # 1. Collecter les mÃ©tadonnÃ©es de tous les documents
        all_docs = self.list_documents()

        # 2. Filtrer selon le scope
        filtered_docs = self._filter_documents_by_scope(all_docs, scope)

        if not filtered_docs:
            return {"error": f"Aucun document trouvÃ© pour le scope '{scope}'"}

        print(f"ðŸ“Š Analyse de {len(filtered_docs)} documents...")

        # 3. Analyser les concepts globaux
        global_concepts = await self._analyze_global_concepts(filtered_docs)

        # 4. Identifier les thÃ¨mes principaux
        themes = self._identify_main_themes(filtered_docs, global_concepts)

        # 5. GÃ©nÃ©rer le rÃ©sumÃ© textuel
        summary_text = await self._generate_summary_text(filtered_docs, global_concepts, themes)

        # 6. Compiler les statistiques
        statistics = self._compile_global_statistics(filtered_docs, global_concepts)

        return {
            "summary": summary_text,
            "main_concepts": global_concepts[:20],  # Top 20
            "themes": themes,
            "statistics": statistics,
            "documents_analyzed": len(filtered_docs)
        }

    def _filter_documents_by_scope(self, docs: List[Dict], scope: str) -> List[Dict]:
        """Filtre les documents selon le scope"""

        if scope == 'all':
            return docs

        if scope.startswith('project:'):
            project_name = scope.split(':', 1)[1]
            return [doc for doc in docs if doc.get('project', '').lower() == project_name.lower()]

        if scope.startswith('type:'):
            file_type = scope.split(':', 1)[1]
            return [doc for doc in docs if doc.get('file_type', '').lower() == file_type.lower()]

        # Scope comme nom de projet par dÃ©faut
        return [doc for doc in docs if scope.lower() in doc.get('project', '').lower()]

    async def _analyze_global_concepts(self, documents: List[Dict]) -> List[Dict[str, Any]]:
        """Analyse les concepts dans tous les documents"""

        concept_frequency = {}  # concept_uri -> {count, total_confidence, labels}

        for doc in documents:
            doc_concepts = doc.get('ontology_concepts', [])

            # Aussi rÃ©cupÃ©rer les concepts des chunks si disponible
            doc_id = doc.get('document_id')
            if doc_id and doc_id in self.rag_engine.document_store.document_chunks:
                chunks = self.rag_engine.document_store.document_chunks[doc_id]
                for chunk in chunks:
                    detected_concepts = chunk.get('metadata', {}).get('detected_concepts', [])
                    for concept in detected_concepts:
                        uri = concept.get('concept_uri', '')
                        label = concept.get('label', '')
                        confidence = concept.get('confidence', 0)

                        if uri:
                            if uri not in concept_frequency:
                                concept_frequency[uri] = {
                                    'count': 0,
                                    'total_confidence': 0,
                                    'labels': set(),
                                    'documents': set()
                                }

                            concept_frequency[uri]['count'] += 1
                            concept_frequency[uri]['total_confidence'] += confidence
                            concept_frequency[uri]['labels'].add(label)
                            concept_frequency[uri]['documents'].add(doc.get('filename', 'Unknown'))

        # Convertir en liste triÃ©e
        global_concepts = []
        for uri, stats in concept_frequency.items():
            if stats['count'] > 0:  # Au moins une occurrence
                avg_confidence = stats['total_confidence'] / stats['count']
                primary_label = list(stats['labels'])[0] if stats['labels'] else uri.split('#')[-1]

                global_concepts.append({
                    'concept_uri': uri,
                    'label': primary_label,
                    'frequency': stats['count'],
                    'avg_confidence': avg_confidence,
                    'document_count': len(stats['documents']),
                    'documents': list(stats['documents']),
                    'importance_score': stats['count'] * avg_confidence * len(stats['documents'])
                })

        # Trier par score d'importance
        global_concepts.sort(key=lambda x: x['importance_score'], reverse=True)
        return global_concepts

    def _identify_main_themes(self, documents: List[Dict], concepts: List[Dict]) -> Dict[str, List[str]]:
        """Identifie les thÃ¨mes principaux"""

        themes = {}

        # ThÃ¨mes par type de fichier
        file_types = {}
        for doc in documents:
            file_type = doc.get('file_type', 'unknown')
            if file_type not in file_types:
                file_types[file_type] = []
            file_types[file_type].append(doc.get('filename', 'Unknown'))

        for file_type, files in file_types.items():
            if len(files) > 1:  # Au moins 2 fichiers
                themes[f"Documents {file_type}"] = files

        # ThÃ¨mes par concepts dominants
        for concept in concepts[:5]:  # Top 5 concepts
            if concept['document_count'] > 1:  # Dans plusieurs documents
                theme_name = f"ThÃ¨me: {concept['label']}"
                themes[theme_name] = concept['documents']

        # ThÃ¨mes par projet
        projects = {}
        for doc in documents:
            project = doc.get('project', 'Unknown')
            if project not in projects:
                projects[project] = []
            projects[project].append(doc.get('filename', 'Unknown'))

        for project, files in projects.items():
            if len(files) > 1 and project != 'Unknown':
                themes[f"Projet: {project}"] = files

        return themes

    async def _generate_summary_text(self, documents: List[Dict], concepts: List[Dict], themes: Dict) -> str:
        """GÃ©nÃ¨re le texte de rÃ©sumÃ©"""

        # CrÃ©er un prompt pour le LLM
        doc_list = "\n".join(
            [f"- {doc.get('filename', 'Unknown')} ({doc.get('file_type', 'unknown')})" for doc in documents])

        main_concepts_text = "\n".join(
            [f"- {c['label']} (prÃ©sent dans {c['document_count']} documents)" for c in concepts[:10]])

        themes_text = "\n".join([f"- {theme}: {len(files)} documents" for theme, files in themes.items()])

        prompt = f"""GÃ©nÃ¨re un rÃ©sumÃ© exÃ©cutif des documents suivants :

    DOCUMENTS ANALYSÃ‰S ({len(documents)} au total):
    {doc_list}

    CONCEPTS PRINCIPAUX DÃ‰TECTÃ‰S:
    {main_concepts_text}

    THÃˆMES IDENTIFIÃ‰S:
    {themes_text}

    CrÃ©e un rÃ©sumÃ© structurÃ© qui inclut :
    1. Vue d'ensemble du contenu
    2. Domaines scientifiques/techniques couverts
    3. Types de documents et leur rÃ©partition
    4. Concepts clÃ©s et leur importance
    5. Connections entre les diffÃ©rents documents

    Sois concis mais informatif, en 3-4 paragraphes maximum."""

        try:
            # Utiliser le LLM pour gÃ©nÃ©rer le rÃ©sumÃ©
            summary = await self.rag_engine.llm_provider.generate_response(prompt)
            return summary
        except Exception as e:
            print(f"âš ï¸ Erreur gÃ©nÃ©ration LLM: {e}")

            # Fallback : rÃ©sumÃ© automatique simple
            return self._generate_simple_summary(documents, concepts, themes)

    def _generate_simple_summary(self, documents: List[Dict], concepts: List[Dict], themes: Dict) -> str:
        """GÃ©nÃ¨re un rÃ©sumÃ© simple en fallback"""

        file_types = {}
        projects = set()

        for doc in documents:
            file_type = doc.get('file_type', 'unknown')
            file_types[file_type] = file_types.get(file_type, 0) + 1
            projects.add(doc.get('project', 'Unknown'))

        summary = f"""RÃ‰SUMÃ‰ DES DOCUMENTS

    ðŸ“Š STATISTIQUES:
    - {len(documents)} documents analysÃ©s
    - {len(concepts)} concepts uniques dÃ©tectÃ©s
    - {len(projects)} projets reprÃ©sentÃ©s
    - Types de fichiers: {', '.join([f"{t}({n})" for t, n in file_types.items()])}

    ðŸ§  CONCEPTS PRINCIPAUX:
    {chr(10).join([f"â€¢ {c['label']} - prÃ©sent dans {c['document_count']} documents" for c in concepts[:5]])}

    ðŸŽ¯ THÃˆMES IDENTIFIÃ‰S:
    {chr(10).join([f"â€¢ {theme}: {len(files)} documents" for theme, files in list(themes.items())[:5]])}

    Cette collection de documents couvre principalement {', '.join(list(projects))} avec un focus sur les concepts de {', '.join([c['label'] for c in concepts[:3]])}."""

        return summary

    def _compile_global_statistics(self, documents: List[Dict], concepts: List[Dict]) -> Dict[str, Any]:
        """Compile les statistiques globales"""

        file_types = {}
        projects = {}
        total_chunks = 0

        for doc in documents:
            # Types de fichiers
            file_type = doc.get('file_type', 'unknown')
            file_types[file_type] = file_types.get(file_type, 0) + 1

            # Projets
            project = doc.get('project', 'Unknown')
            projects[project] = projects.get(project, 0) + 1

            # Chunks
            total_chunks += doc.get('total_chunks', 0)

        # Domaines des concepts
        domains = set()
        for concept in concepts:
            uri = concept['concept_uri']
            if '#' in uri:
                domain = uri.rsplit('#', 1)[0].split('/')[-1]
                domains.add(domain)

        return {
            'total_documents': len(documents),
            'total_chunks': total_chunks,
            'file_types': file_types,
            'projects': projects,
            'domains': list(domains),
            'main_concepts': [c['label'] for c in concepts[:10]],
            'avg_concepts_per_doc': len(concepts) / len(documents) if documents else 0
        }

    async def hierarchical_query(self, query: str, max_per_level: int = 3, mode: str = 'auto') -> Dict[str, Any]:
        """RequÃªte hiÃ©rarchique intelligente avec auto-dÃ©tection de contenu"""

        #print(f"ðŸ” RequÃªte hiÃ©rarchique intelligente: {query}")

        # CrÃ©er le moteur unifiÃ©
        entity_manager = None
        if (hasattr(self.custom_processor, 'fortran_processor') and
                self.custom_processor.fortran_processor and
                hasattr(self.custom_processor.fortran_processor, 'entity_manager')):
            entity_manager = self.custom_processor.fortran_processor.entity_manager

        conceptual_engine = ConceptualHierarchicalEngine(
            self.rag_engine.document_store,
            self.rag_engine.embedding_manager.provider,
            entity_manager
        )

        # Recherche intelligente
        conceptual_results = await conceptual_engine.intelligent_hierarchical_search(
            query, max_per_level, mode
        )

        # PrÃ©parer les passages pour la gÃ©nÃ©ration de rÃ©ponse
        all_passages = []
        source_descriptions = []
        source_index = 0

        hierarchical_results = conceptual_results.get('hierarchical_results', {})
        search_mode = conceptual_results.get('search_mode', 'unified')

        for conceptual_level, level_data in hierarchical_results.items():
            results = level_data['results']
            display_name = level_data['display_name']

            for result in results:
                source_index += 1

                # Adapter selon le type de rÃ©sultat
                if 'entity' in result:
                    # RÃ©sultat Fortran
                    entity = result['entity']
                    source_desc = (
                        f"[Source {source_index}] {entity.filename} "
                        f"(lignes {entity.start_line}-{entity.end_line}) "
                        f"- {entity.entity_type}: {entity.entity_name}"
                    )

                    # RÃ©cupÃ©rer le texte de l'entitÃ©
                    text_content = await self._get_entity_text_content(entity)

                    passage = {
                        'text': text_content,
                        'similarity': result['similarity'],
                        'level': conceptual_level,
                        'source_index': source_index,
                        'source_info': result['source_info'],
                        'source_description': source_desc,
                        'content_type': 'fortran'
                    }

                else:
                    # RÃ©sultat texte
                    chunk = result['chunk']
                    source_info = result['source_info']
                    source_desc = (
                        f"[Source {source_index}] {source_info['filename']} "
                        f"(lignes {source_info['start_line']}-{source_info['end_line']}) "
                        f"- {source_info['section_title']}"
                    )

                    passage = {
                        'text': chunk['text'],
                        'similarity': result['similarity'],
                        'level': conceptual_level,
                        'source_index': source_index,
                        'source_info': source_info,
                        'source_description': source_desc,
                        'content_type': source_info.get('content_type', 'text')
                    }

                source_descriptions.append(source_desc)
                all_passages.append(passage)

        # GÃ©nÃ©rer le prompt systÃ¨me adaptÃ©
        system_prompt = f"""Tu es un assistant expert qui rÃ©pond aux questions en citant TOUJOURS ses sources.

    Mode de recherche utilisÃ©: {search_mode}

    Tu as accÃ¨s aux sources suivantes:
    {chr(10).join(source_descriptions)}

    INSTRUCTIONS IMPORTANTES:
    1. RÃ©ponds Ã  la question en utilisant uniquement les informations fournies
    2. Cite OBLIGATOIREMENT tes sources en utilisant [Source N] dans ta rÃ©ponse
    3. Adapte ton langage selon le type de contenu (technique pour Fortran, descriptif pour texte)
    4. Structure ta rÃ©ponse selon la hiÃ©rarchie trouvÃ©e
    5. N'invente aucune information

    Exemple de citation: "D'aprÃ¨s [Source 1] dans le module my_module (lignes 45-67)..."
    """

        # GÃ©nÃ©rer la rÃ©ponse
        answer = await self.rag_engine.generate_answer(query, all_passages, system_prompt)

        return {
            "answer": answer,
            "search_mode": search_mode,
            "hierarchical_results": hierarchical_results,
            "total_passages": len(all_passages),
            "conceptual_levels_found": list(hierarchical_results.keys())
        }

    async def _get_entity_text_content(self, entity) -> str:
        """RÃ©cupÃ¨re le contenu textuel d'une entitÃ© Fortran"""
        try:
            if entity.chunks:
                # ConcatÃ©ner le texte de tous les chunks
                text_parts = []
                for chunk_info in entity.chunks:
                    chunk_id = chunk_info.get('chunk_id')
                    if chunk_id:
                        chunk = await self._get_chunk_by_id(chunk_id)
                        if chunk:
                            text_parts.append(chunk.get('text', ''))

                return '\n'.join(text_parts) if text_parts else f"EntitÃ© {entity.entity_name} (contenu non disponible)"
            else:
                return f"EntitÃ© {entity.entity_name} de type {entity.entity_type}"
        except Exception as e:
            return f"EntitÃ© {entity.entity_name} (erreur rÃ©cupÃ©ration: {e})"

    async def _get_chunk_by_id(self, chunk_id: str) -> Optional[Dict[str, Any]]:
        """RÃ©cupÃ¨re un chunk par son ID"""
        for doc_id, chunks in self.rag_engine.document_store.document_chunks.items():
            for chunk in chunks:
                if chunk['id'] == chunk_id:
                    return chunk
        return None

    async def diagnose_fortran_entity_manager(self) -> Dict[str, Any]:
        """Diagnostic de l'EntityManager Fortran"""
        try:
            return await self.rag_engine.diagnose_fortran_entity_manager()

        except Exception as e:
            return {"error": f"Erreur diagnostic: {str(e)}"}

    async def get_fortran_context(self, entity_name: str,
                                  agent_type: str = "developer",
                                  task_context: str = "code_understanding",
                                  context_type: str = "smart") -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re le contexte Fortran pour une entitÃ© via le module d'analyse.
        """
        try:
            # AccÃ©der au processeur Fortran via le document processor
            fortran_processor = self.custom_processor.fortran_processor

            if not fortran_processor:
                return {"error": "Module Fortran non initialisÃ©"}

            if context_type == "smart":
                # Utiliser l'orchestrateur intelligent
                return await fortran_processor.get_entity_context(entity_name, "smart")
            else:
                # Contexte spÃ©cifique
                return await fortran_processor.get_entity_context(entity_name, context_type)

        except Exception as e:
            return {"error": f"Erreur rÃ©cupÃ©ration contexte: {str(e)}"}

    async def search_fortran_entities(self, query: str) -> List[Dict[str, Any]]:
        """Recherche d'entitÃ©s Fortran"""
        try:
            fortran_processor = self.custom_processor.fortran_processor
            if not fortran_processor:
                return []

            return await fortran_processor.search_entities(query)

        except Exception as e:
            print(f"Erreur recherche entitÃ©s: {e}")
            return []

    async def generate_dependency_visualization(self,
                                                output_file: str = "dependencies.html",
                                                max_entities: int = 50,
                                                include_variables: bool = True,
                                                focus_entity: str = None) -> Optional[str]:
        """GÃ©nÃ¨re une visualisation des dÃ©pendances"""
        try:
            from fortran_analysis.output.graph_visualizer import create_dependency_visualization_from_parser

            # RÃ©cupÃ©rer toutes les entitÃ©s
            fortran_processor = self.custom_processor.fortran_processor
            if not fortran_processor or not fortran_processor.entity_manager:
                return None

            # RÃ©cupÃ©rer les entitÃ©s depuis EntityManager
            all_entities = list(fortran_processor.entity_manager.entities.values())

            if not all_entities:
                print("Aucune entitÃ© trouvÃ©e pour la visualisation")
                return None

            # GÃ©nÃ©rer la visualisation
            html_file = create_dependency_visualization_from_parser(
                entities=all_entities,
                output_file=output_file,
                focus_entity=focus_entity,
                include_variables=include_variables,
                max_entities=max_entities
            )

            return html_file

        except Exception as e:
            print(f"Erreur gÃ©nÃ©ration visualisation: {e}")
            return None

    async def refresh_fortran_index(self):
        """RÃ©indexe le module Fortran"""
        try:
            fortran_processor = self.custom_processor.fortran_processor
            if fortran_processor and fortran_processor.entity_manager:
                await fortran_processor.entity_manager.rebuild_index()

        except Exception as e:
            print(f"Erreur rÃ©indexation: {e}")
            raise

    async def get_fortran_stats(self) -> Dict[str, Any]:
        """Statistiques du module Fortran"""
        try:
            fortran_processor = self.custom_processor.fortran_processor
            if not fortran_processor:
                return {"error": "Module Fortran non initialisÃ©"}

            return fortran_processor.get_stats()

        except Exception as e:
            return {"error": f"Erreur rÃ©cupÃ©ration stats: {str(e)}"}

    async def get_text_generator(self):
        """RÃ©cupÃ¨re ou crÃ©e le gÃ©nÃ©rateur de texte contextuel"""
        if not hasattr(self, 'text_generator') or self.text_generator is None:
            from fortran_analysis.output.text_generator import ContextualTextGenerator

            self.text_generator = ContextualTextGenerator(
                self.rag_engine.document_store,
                self.rag_engine
            )
            await self.text_generator.initialize()

        return self.text_generator

    async def generate_contextual_text(self,
                                       element_name: str,
                                       context_type: str = "complete",
                                       agent_perspective: str = "developer",
                                       task_context: str = "code_understanding",
                                       format_style: str = "detailed") -> str:
        """Interface pour gÃ©nÃ©rer du texte contextuel"""
        try:
            text_generator = await self.get_text_generator()

            return await text_generator.get_contextual_text(
                element_name=element_name,
                context_type=context_type,
                agent_perspective=agent_perspective,
                task_context=task_context,
                format_style=format_style
            )

        except Exception as e:
            return f"âŒ Erreur gÃ©nÃ©ration texte: {str(e)}"

    # MÃ©thodes de convenance
    async def get_quick_text(self, element_name: str) -> str:
        """Texte rapide en bullet points"""
        text_generator = await self.get_text_generator()
        return await text_generator.get_quick_context(element_name)

    async def get_full_text(self, element_name: str) -> str:
        """Texte complet dÃ©taillÃ©"""
        text_generator = await self.get_text_generator()
        return await text_generator.get_full_context(element_name)

    async def get_developer_text(self, element_name: str, task: str = "code_understanding") -> str:
        """Texte optimisÃ© dÃ©veloppeur"""
        text_generator = await self.get_text_generator()
        return await text_generator.get_developer_context(element_name, task)

    async def get_reviewer_text(self, element_name: str) -> str:
        """Texte optimisÃ© reviewer"""
        text_generator = await self.get_text_generator()
        return await text_generator.get_reviewer_context(element_name)

    def _load_metadata(self) -> Dict[str, Dict[str, Any]]:
        """Charge les mÃ©tadonnÃ©es des documents"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"Erreur lors du chargement des mÃ©tadonnÃ©es: {e}")
        return {}

    def _save_metadata(self):
        """Sauvegarde les mÃ©tadonnÃ©es des documents"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.documents_metadata, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"Erreur lors de la sauvegarde des mÃ©tadonnÃ©es: {e}")

    def _get_file_type(self, filepath: str) -> str:
        """DÃ©termine le type de fichier basÃ© sur l'extension"""
        extension = Path(filepath).suffix.lower()
        return self.file_extensions.get(extension, 'text')

    def _calculate_file_hash(self, filepath: str) -> str:
        """Calcule le hash MD5 d'un fichier"""
        hash_md5 = hashlib.md5()
        try:
            with open(filepath, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
        except Exception as e:
            self.logger.error(f"Erreur lors du calcul du hash pour {filepath}: {e}")
            return ""
        return hash_md5.hexdigest()

    def _get_document_id(self, filepath: str) -> str:
        """GÃ©nÃ¨re un ID unique pour un document"""
        path = Path(filepath).resolve()
        return str(path).replace('/', '_').replace('\\', '_').replace(':', '').replace(' ', '_')

    async def add_document(
            self,
            filepath: str,
            project_name: Optional[str] = None,
            version: Optional[str] = None,
            additional_metadata: Optional[Dict[str, Any]] = None,
            force_update: bool = False
    ) -> bool:
        """Version optimisÃ©e avec classification intÃ©grÃ©e au chunking"""

        if not await self._ensure_initialized():
            return False

        filepath = str(Path(filepath).resolve())
        if not os.path.exists(filepath):
            self.logger.error(f"Fichier non trouvÃ©: {filepath}")
            return False

        doc_id = self._get_document_id(filepath)

        # VÃ©rifier si le fichier a changÃ©
        current_hash = self._calculate_file_hash(filepath)
        if not force_update and doc_id in self.documents_metadata:
            if self.documents_metadata[doc_id].get('file_hash') == current_hash:
                print(f"ðŸ“„ {Path(filepath).name} - Aucun changement dÃ©tectÃ©")
                return True

        print(f"ðŸ“ Traitement de {Path(filepath).name}...")

        try:
            # PrÃ©parer les mÃ©tadonnÃ©es
            additional_meta = {
                'project': project_name or "Unknown",
                'version': version or "1.0",
                'file_type': self._get_file_type(filepath),
                'file_hash': current_hash
            }
            if additional_metadata:
                additional_meta.update(additional_metadata)

            # Ajouter le document - la classification se fait PENDANT le chunking
            doc_id_result = await self.rag_engine.document_store.add_document_with_id(
                filepath, doc_id, additional_meta
            )

            if doc_id in self.rag_engine.document_store.document_chunks:
                chunks = self.rag_engine.document_store.document_chunks[doc_id]

                # Analyser les rÃ©solutions d'ambiguÃ¯tÃ©
                resolved_ambiguities = []
                for chunk in chunks:
                    detected_concepts = chunk.get('metadata', {}).get('detected_concepts', [])
                    for concept in detected_concepts:
                        if concept.get('ambiguity_resolved'):
                            resolved_ambiguities.append({
                                'label': concept['label'],
                                'chosen_uri': concept['concept_uri'],
                                'final_confidence': concept.get('final_confidence', concept['confidence']),
                                'context_score': concept.get('context_score', 0)
                            })

                if resolved_ambiguities:
                    print(f"ðŸŽ¯ AmbiguÃ¯tÃ©s rÃ©solues pour {Path(filepath).name}:")
                    for resolution in resolved_ambiguities[:3]:  # Top 3
                        context_info = f"contexte: {resolution['context_score']:+.2f}" if resolution[
                                                                                              'context_score'] != 0 else ""
                        chosen_concept = resolution['chosen_uri'].split('#')[-1]
                        print(
                            f"   - '{resolution['label']}' â†’ {chosen_concept} (conf: {resolution['final_confidence']:.2f}, {context_info})")
            # Collecter les concepts depuis les chunks
            all_concepts = {}

            if doc_id in self.rag_engine.document_store.document_chunks:
                chunks = self.rag_engine.document_store.document_chunks[doc_id]

                for chunk in chunks:
                    detected_concepts = chunk.get('metadata', {}).get('detected_concepts', [])

                    for concept in detected_concepts:
                        uri = concept.get('concept_uri', '')
                        if uri:
                            if uri not in all_concepts:
                                all_concepts[uri] = {
                                    'label': concept.get('label', ''),
                                    'total_confidence': 0,
                                    'count': 0
                                }
                            all_concepts[uri]['total_confidence'] += concept.get('confidence', 0)
                            all_concepts[uri]['count'] += 1

            # AgrÃ©ger les concepts au niveau document
            document_concepts = []
            for uri, stats in all_concepts.items():
                avg_confidence = stats['total_confidence'] / stats['count'] if stats['count'] > 0 else 0
                document_concepts.append({
                    'uri': uri,
                    'label': stats['label'],
                    'confidence': avg_confidence,
                    'frequency': stats['count']
                })

            # Trier par score (confidence Ã— frequency)
            document_concepts.sort(
                key=lambda x: x['confidence'] * (x['frequency'] / len(chunks) if chunks else 1),
                reverse=True
            )

            # Mettre Ã  jour les mÃ©tadonnÃ©es
            self.documents_metadata[doc_id] = {
                'document_id': doc_id,
                'filepath': filepath,
                'filename': Path(filepath).name,
                'last_updated': datetime.now().isoformat(),
                'ontology_concepts': [c['label'] for c in document_concepts[:20]],
                'ontology_classified': True,
                'total_chunks': len(chunks) if doc_id in self.rag_engine.document_store.document_chunks else 0,
                **additional_meta
            }

            self._save_metadata()
            print(f"âœ… {Path(filepath).name} ajoutÃ© avec succÃ¨s!")
            print(
                f"ðŸ“Š {len(document_concepts)} concepts uniques dÃ©tectÃ©s dans {self.documents_metadata[doc_id]['total_chunks']} chunks")

            return True

        except Exception as e:
            self.logger.error(f"Erreur lors de l'ajout de {filepath}: {e}")
            import traceback
            traceback.print_exc()
            return False

    async def _add_document_with_chunks(
            self,
            filepath: str,
            doc_id: str,
            chunks: List[Dict[str, Any]],
            metadata: Dict[str, Any]
    ) -> bool:
        """Ajoute un document avec des chunks prÃ©-traitÃ©s"""
        try:
            # Copier le fichier
            filename = Path(filepath).name
            document_path = Path(self.rag_engine.document_store.documents_dir) / f"{doc_id}_{filename}"

            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, lambda: shutil.copy2(filepath, str(document_path)))

            # Stocker les mÃ©tadonnÃ©es du document
            self.rag_engine.document_store.documents[doc_id] = {
                "id": doc_id,
                "path": str(document_path),
                "original_path": filepath,
                "original_filename": filename,
                "chunks_count": len(chunks),
                "additional_metadata": metadata
            }

            # Stocker les chunks
            self.rag_engine.document_store.document_chunks[doc_id] = chunks

            # Sauvegarder les chunks sur disque
            chunks_path = await self.rag_engine.document_store.save_chunks(doc_id)

            # CrÃ©er et sauvegarder les embeddings
            await self.rag_engine.embedding_manager.create_embeddings(chunks)
            await self.rag_engine.embedding_manager.save_embeddings(doc_id)

            # Sauvegarder les mÃ©tadonnÃ©es
            await self.rag_engine.document_store._save_metadata()

            return True

        except Exception as e:
            print(f"âŒ Erreur lors de l'ajout du document avec chunks: {e}")
            return False

    async def query(
            self,
            question: str,
            max_results: int = 5,
            file_types: Optional[List[str]] = None,
            projects: Optional[List[str]] = None,
            use_ontology: bool = True
    ) -> Dict[str, Any]:
        """Effectue une requÃªte dans le RAG"""
        if not await self._ensure_initialized():
            return {"error": "RAG non initialisÃ©"}

        print(f"ðŸ” Recherche: {question}")

        try:
            if use_ontology and self.classifier:
                # Utiliser la nouvelle mÃ©thode simple
                result = await self.classifier.search_with_concepts(
                    query=question,
                    top_k=max_results,
                    concept_weight=0.3  # 30% concepts, 70% similaritÃ© textuelle
                )

                # Filtrer par type/projet si nÃ©cessaire
                if file_types or projects:
                    filtered_passages = []
                    for passage in result.get("passages", []):
                        metadata = passage.get("metadata", {})

                        if file_types and metadata.get("file_type") not in file_types:
                            continue
                        if projects and metadata.get("project") not in projects:
                            continue

                        filtered_passages.append(passage)

                    result["passages"] = filtered_passages

                return result
            else:
                # Recherche standard sans ontologie
                # TODO fonction Ã  faire !
                result = await self.rag_engine.chat(question, max_results)
                return self._format_standard_result(result)

        except Exception as e:
            self.logger.error(f"Erreur lors de la requÃªte: {e}")
            return {"error": f"Erreur lors de la requÃªte: {str(e)}"}

    async def ask(self, query: str):
        """
        Point d'entrÃ©e unifiÃ© pour toutes les questions.
        Route la requÃªte vers le bon outil et formate la sortie.
        """
        # Le routeur dÃ©cide quoi faire
        result = await self.router.route_query(query)

        # Maintenant, on gÃ¨re la sortie en fonction du type de rÃ©sultat
        result_type = result.get("type")

        if result_type == "entity_list":
            print("\n--- LISTE D'ENTITÃ‰S CORRESPONDANTES ---")
            entities_found = result.get("data", [])
            if not entities_found:
                print("  -> Aucune entitÃ© trouvÃ©e.")
            for item in entities_found:
                entity = item['entity']
                score = item['score']
                print(f"  - {entity.entity_type:<12} {entity.entity_name:<30} "
                      f"(Fichier: {entity.filename}, Score: {score:.2f})")

        elif result_type == "entity_report":
            report_data = result.get("data", {})

            # 1. Transformer le rapport en contexte textuel propre
            context_string = await self._format_report_for_llm(report_data)

            # TODO pourquoi faire _generate_natural... alors que nous le faisons plus bas ?
            # 2. Demander au LLM de synthÃ©tiser ce contexte pour rÃ©pondre Ã  la question
            final_answer = await self._generate_natural_language_response(query, context_string)

            # 3. Afficher la rÃ©ponse en langage naturel
            print(f"ðŸ¤– RÃ©ponse: {final_answer}")

        elif result_type == "conceptual_search":
            # Le routeur a demandÃ© de lancer une recherche conceptuelle
            print("Action: Lancement de la recherche conceptuelle...")
            conceptual_result = await self.hierarchical_query(query)
            # Affichez ce rÃ©sultat avec votre fonction existante
            await display_intelligent_hierarchical_result(conceptual_result)

        elif result_type == "entity_relations":
            # Extraire les informations du rÃ©sultat
            entity = result.get('entity', {})
            relation_type = result.get('relation_type')
            data = result.get('data')
            entity_name = entity.get('name', 'Inconnu')

            # PrÃ©parer le contexte pour le LLM gÃ©nÃ©rateur
            context = ""
            if not data:
                context = f"L'information demandÃ©e n'a pas Ã©tÃ© trouvÃ©e. L'entitÃ© '{entity_name}' n'a aucune relation de type '{relation_type}' dans la base de connaissance."
            else:
                context = f"Voici les informations trouvÃ©es concernant l'entitÃ© '{entity_name}' pour la question : '{query}'.\n"

                if relation_type == 'callers':
                    context += "Cette entitÃ© est appelÃ©e par les entitÃ©s suivantes:\n"
                    # data est une liste de dictionnaires
                    for caller in data:
                        context += (f"- Nom: {caller.get('name')}, Type: {caller.get('type')}, "
                                    f"Fichier: {caller.get('file', 'N/A')}, "
                                    f"Ã  la Ligne: {caller.get('call_line', '?')}\n")  # Utilise call_line

                elif relation_type == 'callees':
                    # data est un dictionnaire
                    calls = data.get('called_functions_or_subroutines', [])
                    deps = data.get('module_dependencies (USE)', [])
                    if calls:
                        context += "Cette entitÃ© appelle les fonctions/subroutines suivantes:\n"
                        # 'calls' est maintenant une liste de dictionnaires
                        for c in calls:
                            context += f"- Nom: {c.get('name')}, Ã  la ligne {c.get('line', '?')}\n"
                    if deps:
                        context += f"Cette entitÃ© dÃ©pend (USE) des modules suivants: {', '.join(deps)}\n"

            # GÃ©nÃ©rer la rÃ©ponse finale en langage naturel
            final_answer = await self._generate_natural_language_response(query, context)
            print(f"ðŸ¤– RÃ©ponse: {final_answer}")

        elif result_type == "unknown" or result_type == "error":
            print(f"\n--- ERREUR OU REQUÃŠTE INCONNUE ---")
            print(f"  -> {result.get('message')}")

        else:
            print("Type de rÃ©sultat inattendu.")

    async def _format_report_for_llm(self, report: dict) -> str:
        """
        Transforme le dictionnaire de rapport complet en une chaÃ®ne de caractÃ¨res
        structurÃ©e et lisible, idÃ©ale pour servir de contexte Ã  un LLM.
        """
        if not report or report.get("error"):
            return f"Le rapport n'a pas pu Ãªtre gÃ©nÃ©rÃ©. Erreur: {report.get('error', 'inconnue')}"

        # Utilisation d'une liste de chaÃ®nes pour construire le contexte
        context_parts = []

        entity_name = report.get("entity_name", "Inconnu")
        context_parts.append(f"### Rapport d'Analyse pour l'EntitÃ© : {entity_name}\n")

        # Section RÃ©sumÃ©
        summary = report.get('summary', {})
        if summary:
            context_parts.append("#### RÃ©sumÃ©\n")
            for key, value in summary.items():
                context_parts.append(f"- {key.replace('_', ' ').capitalize()}: {value}")
            context_parts.append("")  # Ligne vide pour l'espacement

        # Section Signature Riche
        signature = report.get('rich_signature')
        if signature:
            context_parts.append("#### Signature et Arguments\n```fortran\n" + signature + "\n```\n")

        # Section Relations Sortantes (ce que l'entitÃ© utilise)
        outgoing = report.get('outgoing_relations', {})
        if outgoing:
            context_parts.append("#### Relations Sortantes (ce que cette entitÃ© utilise)\n")
            calls = outgoing.get('called_functions_or_subroutines', [])
            deps = outgoing.get('module_dependencies (USE)', [])
            if calls:
                # On crÃ©e une liste de chaÃ®nes formatÃ©es "nom (ligne X)"
                formatted_calls = [f"{call.get('name', '')} (ligne {call.get('line', '?')})" for call in calls]
                context_parts.append(f"- Appelle : {', '.join(formatted_calls)}")
            else:
                context_parts.append("- Appelle : (Aucun)")

            context_parts.append(f"- DÃ©pend de (USE) : {', '.join(deps) if deps else '(Aucun)'}")
            context_parts.append("")

        # Section Relations Entrantes (qui utilise cette entitÃ©)
        incoming = report.get('incoming_relations', [])
        if incoming:
            context_parts.append("#### Relations Entrantes (qui utilise cette entitÃ©)\n")
            callers = [f"{c['name']} (type: {c['type']})" for c in incoming]
            context_parts.append(f"- Est appelÃ©e par : {', '.join(callers) if callers else '(Personne)'}")
            context_parts.append("")

        # Section Contexte Global (Parent)
        global_ctx = report.get('global_context', {})
        parent = global_ctx.get('parent_entity', {})
        if parent and isinstance(parent, dict):
            context_parts.append(
                f"#### Contexte Global\n- Se situe dans : {parent.get('name')} (type: {parent.get('type')})\n")

        # Section Contexte Local (Enfants)
        local_ctx = report.get('local_context', {})
        children = local_ctx.get('children_entities', [])
        if children:
            child_names = [f"{c['name']} (type: {c['type']})" for c in children]
            context_parts.append(f"#### Contenu de l'entitÃ©\n- Contient les sous-entitÃ©s : {', '.join(child_names)}\n")

        # Section Code Source (extrait)
        source = local_ctx.get('source_code', '')
        if source and "Non demandÃ©" not in source:
            context_parts.append("#### Code Source\n")
            # On ne passe qu'un extrait pour ne pas surcharger le contexte du LLM
            source_lines = source.splitlines()
            snippet = "\n".join(source_lines)
            context_parts.append(f"```fortran\n{snippet}\n```")

        return "\n".join(context_parts)

    async def remove_document(self, filepath: str) -> bool:
        """Supprime un document du RAG"""
        if not await self._ensure_initialized():
            return False

        doc_id = self._get_document_id(filepath)

        if doc_id not in self.documents_metadata:
            self.logger.warning(f"Document non trouvÃ©: {filepath}")
            return False

        try:
            success = await self.rag_engine.remove_document(doc_id)

            if success:
                del self.documents_metadata[doc_id]
                self._save_metadata()
                print(f"ðŸ—‘ï¸  Document supprimÃ©: {Path(filepath).name}")

            return success

        except Exception as e:
            self.logger.error(f"Erreur lors de la suppression de {filepath}: {e}")
            return False

    async def _ensure_initialized(self) -> bool:
        """S'assure que le RAG est initialisÃ©"""
        if self.rag_engine is None:
            await self.initialize()
        return self.rag_engine is not None

    def list_documents(self) -> List[Dict[str, Any]]:
        """Liste tous les documents dans le RAG"""
        return list(self.documents_metadata.values())

    def get_statistics(self) -> Dict[str, Any]:
        """Retourne des statistiques sur le RAG"""
        if not self.documents_metadata:
            return {"message": "Aucun document chargÃ©"}

        file_types = {}
        projects = {}
        for metadata in self.documents_metadata.values():
            file_type = metadata.get('file_type', 'unknown')
            project = metadata.get('project', 'unknown')
            file_types[file_type] = file_types.get(file_type, 0) + 1
            projects[project] = projects.get(project, 0) + 1

        return {
            'total_documents': len(self.documents_metadata),
            'file_types': file_types,
            'projects': projects
        }

    def _flatten_concept_hierarchy(self, concepts_hierarchy: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Aplatit une hiÃ©rarchie de concepts"""
        flattened = []
        for concept in concepts_hierarchy:
            flattened.append(concept)
            if "sub_concepts" in concept:
                flattened.extend(self._flatten_concept_hierarchy(concept["sub_concepts"]))
        return flattened

    async def add_documents_batch(
            self,
            documents_info: List[Dict[str, Any]],
            max_concurrent: int = 3,
            force_update: bool = False,
            preserve_order: bool = False  # NOUVEAU : pour les dÃ©pendances
    ) -> Dict[str, bool]:
        """Ajoute plusieurs documents en parallÃ¨le avec gestion de concurrence amÃ©liorÃ©e"""

        if not await self._ensure_initialized():
            return {}

        # NOUVEAU : Trier par type de fichier (modules avant les autres)
        if preserve_order:
            documents_info = self._sort_documents_by_dependencies(documents_info)

        # NOUVEAU : SÃ©maphore pour l'EntityManager
        entity_manager_semaphore = asyncio.Semaphore(1)  # Un seul Ã  la fois pour l'indexation
        processing_semaphore = asyncio.Semaphore(max_concurrent)

        async def add_single_doc(doc_info):
            async with processing_semaphore:
                filepath = doc_info["filepath"]
                try:
                    # NOUVEAU : VÃ©rifier si c'est un fichier Fortran
                    is_fortran = self._get_file_type(filepath) == 'fortran'

                    if is_fortran:
                        # Pour Fortran, utiliser le sÃ©maphore d'EntityManager
                        async with entity_manager_semaphore:
                            success = await self._add_document_with_entity_protection(
                                filepath, doc_info, force_update
                            )
                    else:
                        # Pour les autres fichiers, traitement standard
                        success = await self.add_document(
                            filepath,
                            project_name=doc_info.get("project_name"),
                            version=doc_info.get("version"),
                            additional_metadata=doc_info.get("additional_metadata"),
                            force_update=force_update
                        )

                    return filepath, success

                except Exception as e:
                    self.logger.error(f"Erreur pour {filepath}: {e}")
                    return filepath, False

        # Lancer en parallÃ¨le
        tasks = [add_single_doc(doc_info) for doc_info in documents_info]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Organiser les rÃ©sultats
        final_results = {}
        success_count = 0

        for result in results:
            if isinstance(result, Exception):
                self.logger.error(f"Exception durant le traitement: {result}")
            else:
                filepath, success = result
                final_results[filepath] = success
                if success:
                    success_count += 1

        # NOUVEAU : Reconstruction des relations aprÃ¨s traitement parallÃ¨le
        if success_count > 0:
            await self._rebuild_entity_relationships()

        if success_count > 0:
            print("ðŸ”„ Synchronisation des index de recherche...")
            try:
                await self.custom_processor.fortran_processor.sync_orchestrator_with_entities()
                print("âœ… Index de recherche synchronisÃ©s")
            except Exception as e:
                print(f"âš ï¸ Erreur synchronisation: {e}")

        print(f"ðŸ“Š Traitement terminÃ©: {success_count}/{len(documents_info)} fichiers ajoutÃ©s avec succÃ¨s")
        return final_results

    async def _add_document_with_entity_protection(
            self,
            filepath: str,
            doc_info: Dict[str, Any],
            force_update: bool
    ) -> bool:
        """Ajoute un document avec protection de l'EntityManager"""
        try:
            return await self.add_document(
                filepath,
                project_name=doc_info.get("project_name"),
                version=doc_info.get("version"),
                additional_metadata=doc_info.get("additional_metadata"),
                force_update=force_update
            )
        except Exception as e:
            self.logger.error(f"Erreur traitement protÃ©gÃ© {filepath}: {e}")
            return False

    def _sort_documents_by_dependencies(self, documents_info: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Trie les documents par ordre de dÃ©pendance (modules en premier)"""
        fortran_modules = []
        fortran_others = []
        non_fortran = []

        for doc_info in documents_info:
            filepath = doc_info["filepath"]
            file_type = self._get_file_type(filepath)

            if file_type == 'fortran':
                # Heuristique simple : les fichiers avec "module" dans le nom en premier
                filename = Path(filepath).name.lower()
                if 'module' in filename or filepath.endswith('_mod.f90'):
                    fortran_modules.append(doc_info)
                else:
                    fortran_others.append(doc_info)
            else:
                non_fortran.append(doc_info)

        # Ordre : modules Fortran â†’ autres Fortran â†’ non-Fortran
        return fortran_modules + fortran_others + non_fortran

    async def _rebuild_entity_relationships(self):
        """Reconstruit les relations entre entitÃ©s aprÃ¨s traitement parallÃ¨le"""
        try:
            if (self.custom_processor and
                    self.custom_processor.fortran_processor and
                    self.custom_processor.fortran_processor.entity_manager):
                entity_manager = self.custom_processor.fortran_processor.entity_manager

                # Reconstruire les relations
                await entity_manager._build_relationships()
                await entity_manager._detect_and_group_split_entities()

                print("âœ… Relations entre entitÃ©s reconstruites")

        except Exception as e:
            self.logger.error(f"Erreur reconstruction relations: {e}")

    async def diagnose_fortran_entity_manager(self) -> Dict[str, Any]:
        """Diagnostic complet de l'EntityManager Fortran"""
        try:
            if not self.custom_processor:
                return {"error": "custom_processor non disponible"}

            if not self.custom_processor.fortran_processor:
                return {"error": "fortran_processor non disponible"}

            return await self.custom_processor.fortran_processor.diagnose_entity_manager()

        except Exception as e:
            return {"error": f"Erreur diagnostic: {str(e)}"}

    async def _generate_natural_language_response(self, original_query: str, context_data: str) -> str:
        """
        Prend des donnÃ©es de contexte et la question originale pour gÃ©nÃ©rer
        une rÃ©ponse finale en langage naturel, en utilisant le provider LLM du RAG.

        Args:
            original_query: La question posÃ©e initialement par l'utilisateur.
            context_data: Les informations brutes rÃ©cupÃ©rÃ©es par les outils, formatÃ©es en texte.

        Returns:
            Une chaÃ®ne de caractÃ¨res contenant la rÃ©ponse synthÃ©tisÃ©e.
        """
        # 1. CrÃ©ation d'un prompt trÃ¨s directif pour la tÃ¢che de synthÃ¨se
        prompt = f"""Tu es un architecte logiciel senior et un expert du langage Fortran. Ta mission est d'analyser le contexte technique fourni pour rÃ©pondre Ã  la question de l'utilisateur de maniÃ¨re synthÃ©tique et avec perspicacitÃ©. Ne te contente pas de lister les faits, explique leur signification.

        INSTRUCTIONS POUR ADAPTER TA RÃ‰PONSE :
Analyse la "Question Originale" et choisis l'un des deux styles de rÃ©ponse suivants :

1.  **Si la question est FACTUELLE (demande qui, quel, combien, oÃ¹) :**
    - RÃ©ponds directement en incluant les dÃ©tails de localisation importants (fichier, lignes) s'ils sont disponibles.
    - Sois concis mais informatif. Ne fais pas d'analyse profonde si elle n'est pas demandÃ©e.
    
    - **EXEMPLE:**
      - Question: "Qui appelle la routine 'Cleanup' ?"
      - Contexte: "Cette entitÃ© est appelÃ©e par les entitÃ©s suivantes:\n- Nom: Finalize_Run, Type: subroutine, Fichier: /path/main.f90, Ã  la Ligne: 525\n"
      - **RÃ©ponse attendue:** "La routine 'Cleanup' est appelÃ©e par la subroutine 'Finalize_Run', Ã  la ligne 525 du fichier `/path/main.f90`."
      
2.  **Si la question est ANALYTIQUE (demande pourquoi, comment, Ã  quoi sert) :**
        a.  **DÃ©termine le But Principal :** En te basant sur le nom de l'entitÃ©, les fonctions qu'elle appelle (surtout `free`, `allocate`, `create`, `destroy`, `init`), et les commentaires dans le code, dÃ©duis la responsabilitÃ© premiÃ¨re de cette entitÃ©.
        b.  **Identifie les OpÃ©rations ClÃ©s :** DÃ©cris les actions les plus importantes effectuÃ©es par le code, en te basant sur les fonctions appelÃ©es et les dÃ©pendances.
        c.  **Analyse le Contexte d'Appel :** Explique pourquoi cette entitÃ© est utilisÃ©e, en regardant qui l'appelle.
        d.  **SynthÃ©tise, Ne RÃ©cite Pas :** Combine ces points dans une rÃ©ponse fluide. Commence par le but principal, puis donne les dÃ©tails pertinents.
        e.  **Source Unique de VÃ©ritÃ© :** Fonde TOUTE ton analyse EXCLUSIVEMENT sur le "Contexte Fourni". N'invente rien.

        ---
        [Contexte Fourni]
        {context_data}
        ---
        [Question Originale de l'Utilisateur]
        {original_query}
        ---

        [Ton Analyse d'Expert]
        """
        try:
            # 2. Appel de votre provider LLM existant
            # Nous passons le prompt complet dans un message utilisateur. C'est une
            # approche robuste pour les tÃ¢ches de gÃ©nÃ©ration en une seule fois.
            response = await self.rag_engine.llm_provider.generate_response(
                messages=[
                    {"role": "user", "content": prompt}
                ],

                temperature=0.3
            )
            return response.strip()

        except Exception as e:
            logging.error(f"Erreur lors de la gÃ©nÃ©ration de la rÃ©ponse en langage naturel: {e}", exc_info=True)
            return "DÃ©solÃ©, une erreur est survenue lors de la formulation de la rÃ©ponse finale."


    async def get_entity_manager_stats(self) -> Dict[str, Any]:
        """Statistiques dÃ©taillÃ©es de l'EntityManager"""
        try:
            if (not self.custom_processor or
                    not self.custom_processor.fortran_processor or
                    not self.custom_processor.fortran_processor.entity_manager):
                return {"error": "EntityManager non disponible"}

            entity_manager = self.custom_processor.fortran_processor.entity_manager

            return {
                "total_entities": len(entity_manager.entities),
                "entities_by_type": dict([(t, len(ids)) for t, ids in entity_manager.type_to_entities.items()]),
                "entities_by_file": dict([(f, len(ids)) for f, ids in entity_manager.file_to_entities.items()]),
                "name_index_size": len(entity_manager.name_to_entity),
                "parent_child_relations": len(entity_manager.parent_to_children),
                "initialized": getattr(entity_manager, '_initialized', False),
                "sample_entities": [
                    {
                        "name": e.entity_name,
                        "type": e.entity_type,
                        "id": e.entity_id,
                        "file": Path(e.filepath).name if e.filepath else "unknown"
                    }
                    for e in list(entity_manager.entities.values())[:10]
                ]
            }

        except Exception as e:
            return {"error": f"Erreur stats: {str(e)}"}

    #  TODO non utilisÃ© pour l'instant
    async def query_parallel_concepts(
            self,
            question: str,
            max_results: int = 5,
            max_concurrent_concepts: int = 5,
            use_ontology: bool = True
    ) -> Dict[str, Any]:
        """RequÃªte optimisÃ©e avec traitement parallÃ¨le des concepts"""

        if not await self._ensure_initialized():
            return {"error": "RAG non initialisÃ©"}

        if use_ontology and self.classifier:
            return await self.classifier.auto_concept_search_optimized(
                query=question,
                top_k=max_results,
                max_concurrent_searches=max_concurrent_concepts
            )
        else:
            return await self.rag_engine.chat(query=question, top_k=max_results)


class DocumentationContextProvider:
    """Orchestrateur spÃ©cialisÃ© pour la gÃ©nÃ©ration de documentation"""

    def __init__(self, onto_rag_instance):
        self.onto_rag = onto_rag_instance
        self.rag_engine = onto_rag_instance.rag_engine

    async def get_module_readme_context(self, module_name: str) -> Dict[str, Any]:
        """GÃ©nÃ¨re un contexte complet pour un README de module"""

        print(f"ðŸ“š GÃ©nÃ©ration du contexte README pour le module: {module_name}")

        # 1. CONTEXTE ARCHITECTURAL (Global) - CORRECTION ICI
        print("ðŸ—ï¸ Analyse architecturale...")
        global_context = await self.onto_rag.get_global_context(module_name, 2000)

        # 2. INTERFACE ET DÃ‰PENDANCES (Local) - CORRECTION ICI
        print("ðŸ”Œ Analyse de l'interface...")
        local_context = await self.onto_rag.get_local_context(module_name, 2000)

        # 3. CONCEPTS SCIENTIFIQUES (Semantic) - CORRECTION ICI
        print("ðŸ§¬ Analyse des concepts...")
        semantic_context = await self.onto_rag.get_semantic_context(module_name, 1500)

        # 4. RECHERCHE ENRICHIE avec le classifier
        print("ðŸŽ¯ Recherche contextuelle...")
        if hasattr(self.onto_rag, 'classifier') and self.onto_rag.classifier:
            search_result = await self.onto_rag.classifier.search_with_concepts(
                query=f"module {module_name} documentation interface usage",
                top_k=8,
                concept_weight=0.3
            )
        else:
            search_result = {}

        # 5. ASSEMBLAGE INTELLIGENT
        readme_context = await self._assemble_readme_context(
            module_name, global_context, local_context, semantic_context, search_result
        )

        return readme_context

    async def _assemble_readme_context(self, module_name: str,
                                       global_ctx: Dict, local_ctx: Dict,
                                       semantic_ctx: Dict, search_result: Dict) -> Dict[str, Any]:
        """Assemble toutes les informations en un contexte structurÃ© pour README"""

        context = {
            "module_name": module_name,
            "description": await self._extract_module_description(local_ctx, search_result),
            "architecture": await self._extract_architectural_info(global_ctx),
            "public_interface": await self._extract_public_interface(local_ctx),
            "dependencies": await self._extract_dependencies_info(local_ctx, global_ctx),
            "scientific_concepts": await self._extract_scientific_concepts(semantic_ctx),
            "usage_examples": await self._extract_usage_examples(search_result),
            "internal_architecture": await self._extract_internal_architecture(local_ctx),
            "maintenance_info": await self._extract_maintenance_info(global_ctx),
            "related_modules": await self._extract_related_modules(global_ctx, semantic_ctx)
        }

        return context

    async def _extract_module_description(self, local_ctx: Dict, search_result: Dict) -> Dict[str, Any]:
        """Extrait la description du module"""
        description = {
            "purpose": "Unknown",
            "main_functionality": [],
            "file_location": "",
            "concepts_detected": []
        }

        if 'main_definition' in local_ctx:
            main_def = local_ctx['main_definition']
            description.update({
                "file_location": main_def.get('location', {}).get('file', ''),
                "signature": main_def.get('signature', ''),
                "concepts_detected": [c.get('label', '') for c in main_def.get('concepts', [])]
            })

        # Extraire la fonctionnalitÃ© depuis les enfants
        children = local_ctx.get('children_context', [])
        description["main_functionality"] = [
            f"{child.get('type', 'procedure')} {child.get('name', 'unknown')}"
            for child in children[:10]  # Top 10
        ]

        # GÃ©nÃ©rer une description intelligente
        if description["concepts_detected"]:
            concepts_str = ", ".join(description["concepts_detected"][:3])
            description["purpose"] = f"Module implementing {concepts_str} functionality"
        elif description["main_functionality"]:
            func_count = len(description["main_functionality"])
            description["purpose"] = f"Module providing {func_count} procedures for computational tasks"

        return description

    async def _extract_architectural_info(self, global_ctx: Dict) -> Dict[str, Any]:
        """Extrait les informations architecturales"""
        arch_info = {
            "role_in_project": "Unknown",
            "impact_level": "low",
            "affected_modules": 0,
            "architectural_style": "unknown"
        }

        if 'impact_analysis' in global_ctx:
            impact = global_ctx['impact_analysis']
            arch_info.update({
                "impact_level": impact.get('risk_level', 'low'),
                "affected_modules": len(impact.get('affected_modules', [])),
                "recommendations": impact.get('recommendations', [])
            })

        if 'project_overview' in global_ctx:
            overview = global_ctx['project_overview']
            arch_info["architectural_style"] = overview.get('architectural_style', 'unknown')

        # InterprÃ©ter le rÃ´le
        if arch_info["impact_level"] == "high":
            arch_info["role_in_project"] = "Core/Foundation module"
        elif arch_info["affected_modules"] > 3:
            arch_info["role_in_project"] = "Shared utility module"
        else:
            arch_info["role_in_project"] = "Specialized module"

        return arch_info

    async def _extract_public_interface(self, local_ctx: Dict) -> Dict[str, Any]:
        """Extrait l'interface publique du module"""
        interface = {
            "public_procedures": [],
            "public_types": [],
            "public_parameters": [],
            "exported_interfaces": []
        }

        # Analyser les enfants pour identifier l'interface publique
        children = local_ctx.get('children_context', [])

        for child in children:
            child_type = child.get('type', '').lower()
            child_name = child.get('name', 'unknown')
            child_signature = child.get('signature', '')

            if child_type in ['subroutine', 'function']:
                interface["public_procedures"].append({
                    "name": child_name,
                    "type": child_type,
                    "signature": child_signature,
                    "summary": child.get('summary', '')[:100] + "..." if child.get('summary') else ""
                })
            elif child_type in ['type', 'type_definition']:
                interface["public_types"].append({
                    "name": child_name,
                    "signature": child_signature
                })

        return interface

    async def _extract_dependencies_info(self, local_ctx: Dict, global_ctx: Dict) -> Dict[str, Any]:
        """Extrait les informations de dÃ©pendances"""
        deps_info = {
            "direct_dependencies": [],
            "dependency_analysis": "",
            "coupling_level": "unknown"
        }

        # DÃ©pendances directes
        immediate_deps = local_ctx.get('immediate_dependencies', [])
        deps_info["direct_dependencies"] = [
            {
                "name": dep.get('name', 'unknown'),
                "type": dep.get('type', 'module'),
                "summary": dep.get('summary', '')[:100] + "..." if dep.get('summary') else ""
            }
            for dep in immediate_deps[:5]  # Top 5
        ]

        # Analyse du couplage
        deps_count = len(immediate_deps)
        if deps_count == 0:
            deps_info["coupling_level"] = "Independent (no dependencies)"
        elif deps_count <= 2:
            deps_info["coupling_level"] = "Low coupling"
        elif deps_count <= 4:
            deps_info["coupling_level"] = "Moderate coupling"
        else:
            deps_info["coupling_level"] = f"High coupling ({deps_count} dependencies)"

        return deps_info

    async def _extract_scientific_concepts(self, semantic_ctx: Dict) -> Dict[str, Any]:
        """Extrait les concepts scientifiques"""
        scientific_info = {
            "main_concepts": [],
            "algorithmic_patterns": [],
            "scientific_domain": "Computational",
            "mathematical_methods": []
        }

        # Concepts principaux
        main_concepts = semantic_ctx.get('main_concepts', [])
        scientific_info["main_concepts"] = [
            {
                "name": concept.get('label', 'unknown'),
                "confidence": concept.get('confidence', 0)
            }
            for concept in main_concepts[:5]
        ]

        # Patterns algorithmiques
        patterns = semantic_ctx.get('algorithmic_patterns', [])
        scientific_info["algorithmic_patterns"] = [
            {
                "pattern": pattern.get('pattern', 'unknown'),
                "description": pattern.get('description', ''),
                "score": pattern.get('score', 0)
            }
            for pattern in patterns[:3]
        ]

        # DÃ©terminer le domaine scientifique
        concept_labels = [c.get('label', '').lower() for c in main_concepts]

        if any('quantum' in label or 'electron' in label for label in concept_labels):
            scientific_info["scientific_domain"] = "Quantum Chemistry/Physics"
        elif any('molecular' in label or 'dynamics' in label for label in concept_labels):
            scientific_info["scientific_domain"] = "Molecular Dynamics"
        elif any('matrix' in label or 'linear' in label for label in concept_labels):
            scientific_info["scientific_domain"] = "Linear Algebra/Numerical Methods"
        elif any('fft' in label or 'fourier' in label for label in concept_labels):
            scientific_info["scientific_domain"] = "Signal Processing/Spectral Methods"

        return scientific_info

    async def _extract_usage_examples(self, search_result: Dict) -> Dict[str, Any]:
        """Extrait des exemples d'utilisation depuis les passages trouvÃ©s"""
        usage = {
            "example_calls": [],
            "typical_workflow": [],
            "integration_patterns": []
        }

        if 'sources' in search_result:
            for source in search_result['sources'][:3]:  # Top 3 sources
                entity_name = source.get('entity_name', '')
                entity_type = source.get('entity_type', '')

                if entity_type in ['subroutine', 'function']:
                    usage["example_calls"].append(f"call {entity_name}(...)")
                elif entity_type == 'module':
                    usage["integration_patterns"].append(f"use {entity_name}")

        return usage

    async def _extract_internal_architecture(self, local_ctx: Dict) -> Dict[str, Any]:
        """Extrait l'architecture interne"""
        internal = {
            "internal_procedures": [],
            "data_structures": [],
            "complexity_analysis": ""
        }

        # Analyser les fonctions appelÃ©es pour comprendre la structure interne
        called_functions = local_ctx.get('called_functions', [])
        internal["internal_procedures"] = [
            {
                "name": func.get('name', 'unknown'),
                "source": func.get('source', 'unknown')
            }
            for func in called_functions[:5]
        ]

        # Analyse de complexitÃ©
        calls_count = len(called_functions)
        if calls_count == 0:
            internal["complexity_analysis"] = "Simple module with minimal internal dependencies"
        elif calls_count <= 3:
            internal["complexity_analysis"] = "Moderate complexity with few internal calls"
        else:
            internal["complexity_analysis"] = f"Complex module with {calls_count} internal function calls"

        return internal

    async def _extract_maintenance_info(self, global_ctx: Dict) -> Dict[str, Any]:
        """Extrait les informations de maintenance"""
        maintenance = {
            "impact_analysis": {},
            "testing_recommendations": [],
            "refactoring_opportunities": []
        }

        if 'impact_analysis' in global_ctx:
            impact = global_ctx['impact_analysis']
            maintenance["impact_analysis"] = {
                "risk_level": impact.get('risk_level', 'unknown'),
                "affected_modules": impact.get('affected_modules', []),
                "recommendations": impact.get('recommendations', [])
            }

        # GÃ©nÃ©rer des recommandations de test
        risk_level = maintenance["impact_analysis"].get('risk_level', 'low')
        if risk_level == 'high':
            maintenance["testing_recommendations"] = [
                "Comprehensive unit testing required",
                "Integration testing with dependent modules",
                "Performance regression testing"
            ]
        elif risk_level == 'medium':
            maintenance["testing_recommendations"] = [
                "Unit testing for public interface",
                "Basic integration testing"
            ]
        else:
            maintenance["testing_recommendations"] = [
                "Basic unit testing sufficient"
            ]

        return maintenance

    async def _extract_related_modules(self, global_ctx: Dict, semantic_ctx: Dict) -> Dict[str, Any]:
        """Extrait les modules liÃ©s"""
        related = {
            "similar_modules": [],
            "dependent_modules": [],
            "semantic_relatives": []
        }

        # Modules similaires depuis le contexte global
        if 'related_modules' in global_ctx:
            related["similar_modules"] = [
                {
                    "name": mod.get('module', 'unknown'),
                    "similarity": mod.get('similarity', 0),
                    "concepts": mod.get('concepts', [])
                }
                for mod in global_ctx['related_modules'][:3]
            ]

        # EntitÃ©s similaires depuis le contexte sÃ©mantique
        if 'similar_entities' in semantic_ctx:
            related["semantic_relatives"] = [
                {
                    "name": entity.get('name', 'unknown'),
                    "similarity": entity.get('similarity', 0),
                    "file": entity.get('file', 'unknown')
                }
                for entity in semantic_ctx['similar_entities'][:3]
            ]

        return related


# PROMPT TEMPLATE pour README
README_TEMPLATE = """Tu es un expert en documentation technique. GÃ©nÃ¨re un README.md professionnel pour ce module Fortran.

CONTEXTE DU MODULE:
{context}

INSTRUCTIONS:
1. CrÃ©e un README.md complet et professionnel
2. Utilise UNIQUEMENT les informations fournies dans le contexte
3. Structure avec des sections claires et des exemples concrets
4. Inclus des badges de statut si appropriÃ©
5. Ajoute une section "Usage" avec des exemples rÃ©alistes basÃ©s sur l'interface publique
6. Mentionne les concepts scientifiques dÃ©tectÃ©s
7. Inclus une section sur l'architecture et les dÃ©pendances
8. Ajoute des recommandations de maintenance si pertinentes

FORMAT ATTENDU:
- Titre et description
- Badges de statut
- Table des matiÃ¨res
- Description dÃ©taillÃ©e
- Installation/Compilation
- Usage avec exemples
- Interface publique (API)
- Architecture et dÃ©pendances  
- Concepts scientifiques
- Maintenance et dÃ©veloppement
- Modules liÃ©s
- Contribution guidelines

Utilise la syntaxe Markdown et rends le README attractif et informatif."""


# Exemple d'utilisation modifiÃ© avec tests du systÃ¨me de contexte
async def example_usage():
    """Exemple d'utilisation d'OntoRAG avec tests du systÃ¨me de contexte"""

    rag = OntoRAG(
        storage_dir=STORAGE_DIR,
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        ontology_path=ONTOLOGY_PATH_TTL
    )

    await rag.initialize()

    documents_info = rag.scan_directory(
        directory_path="/home/yopla/test_real_bigdft/bigdft-suite/psolver/src/",
        file_filters=['f90', 'f95', 'f'],  # Seulement Fortran
        recursive=False,
        project_name="BigDFT",
        version="1.9"
    )

    # Option 3 : Scan de plusieurs rÃ©pertoires
    # all_documents = []
    #
    # # BigDFT Fortran
    # bigdft_files = rag.scan_directory(
    #     "/home/yopla/BigDFT/bigdft/src",
    #     file_filters=['f90', 'f95'],
    #     project_name="BigDFT",
    #     version="1.9"
    # )
    # all_documents.extend(bigdft_files)
    #
    # # Documentation
    # doc_files = rag.scan_directory(
    #     "/home/yopla/docs",
    #     file_filters=['md', 'rst', 'txt'],
    #     project_name="Documentation",
    #     version="1.0"
    # )
    # all_documents.extend(doc_files)
    #
    # documents_info = all_documents

    # Option 4 : Scan avec exclusions personnalisÃ©es
    # documents_info = rag.scan_directory(
    #     directory_path="/home/yopla/test_ambigu",
    #     file_filters=['txt', 'md'],
    #     exclude_patterns=['.git', 'backup', 'old', '.tmp'],
    #     recursive=False,  # Pas de rÃ©cursivitÃ©
    #     project_name="Tests",
    #     version="1.0"
    # )


    """
    documents_info = [
        {
            "filepath": "/home/yopla/test_ambigu/mecanique.txt",
            "project_name": "BigDFT",
            "version": "1.9"
        },
        {
            "filepath": "/home/yopla/test_ambigu/optique.txt",
            "project_name": "BigDFT",
            "version": "1.9"
        },

    ]
    
    """

    # Traitement parallÃ¨le
    results = await rag.add_documents_batch(documents_info, max_concurrent=MAX_CONCURRENT)
    print(f"Ajout terminÃ©: {sum(results.values())}/{len(results)} succÃ¨s")

    # Statistiques
    stats = rag.get_statistics()

    print("\n" + "=" * 100)
    print("ðŸš€ ONTORAG - SYSTÃˆME DE RECHERCHE DOCUMENTAIRE INTELLIGENT")
    print("=" * 100)

    await show_available_commands()

    while True:
        try:
            query = input('\nðŸ’« Commande : ').strip()

            if query.lower() in ['/quit', '/exit', 'quit', 'exit', 'q']:
                print("ðŸ‘‹ Au revoir !")
                break

            elif query in ['/?', '/help', 'help']:
                await show_available_commands()

            # ==================== RECHERCHE ====================
            elif query.startswith('/search '):
                question = query[8:].strip()
                if question:
                    print(f"ðŸ” Recherche ontologique: {question}")
                    result = await rag.query(question, use_ontology=True)
                    await display_query_result(result)

            elif query.startswith('/hierarchical '):
                # Parser la commande avec options
                parts = query[13:].strip().split()
                if not parts:
                    print("âŒ Usage: /hierarchical <question> [--mode=auto|text|fortran|unified]")
                    continue

                # Extraire la question et les options
                question_parts = []
                mode = 'auto'

                for part in parts:
                    if part.startswith('--mode='):
                        mode = part.split('=', 1)[1]
                    else:
                        question_parts.append(part)

                question = ' '.join(question_parts)

                if question:
                    #print(f"ðŸ” Recherche hiÃ©rarchique intelligente: {question} (mode: {mode})")
                    result = await rag.hierarchical_query(question, max_per_level=3, mode=mode)
                    await display_intelligent_hierarchical_result(result)

            elif query.startswith('/find '):
                entity_name = query[6:].strip()
                if entity_name:
                    print(f"ðŸ” Recherche entitÃ© Fortran: {entity_name}")
                    entities = await rag.search_fortran_entities(entity_name)
                    await display_fortran_entities(entities)

            # ==================== GESTION DOCUMENTS ====================

            elif query.startswith('/list'):
                docs = rag.list_documents()
                await display_document_list(docs)

            elif query.startswith('/stats'):
                detail = query[6:].strip()
                if detail == 'fortran':
                    fortran_stats = await rag.get_fortran_stats()
                    print("ðŸ“Š Statistiques Fortran:")
                    print(json.dumps(fortran_stats, indent=2))
                elif detail == 'entity':
                    entity_stats = await rag.get_entity_manager_stats()
                    print("ðŸ“Š Statistiques EntityManager:")
                    print(json.dumps(entity_stats, indent=2))
                else:
                    stats = rag.get_statistics()
                    print("ðŸ“Š Statistiques gÃ©nÃ©rales:")
                    print(json.dumps(stats, indent=2))

            # ==================== OUTILS & DIAGNOSTIC ====================
            elif query.startswith('/diagnostic'):
                component = query[11:].strip()
                if component == 'fortran' or not component:
                    diagnosis = await rag.diagnose_fortran_entity_manager()
                    print("ðŸ” Diagnostic EntityManager:")
                    print(json.dumps(diagnosis, indent=2))

            elif query.startswith('/visualization'):
                print('ðŸŽ¨ GÃ©nÃ©ration visualisation dÃ©pendances...')
                html_file = await rag.generate_dependency_visualization(
                    output_file="dependencies.html",
                    max_entities=2000,
                    include_variables=False
                )
                if html_file:
                    print(f"âœ… GÃ©nÃ©rÃ©: {html_file}")
                    import webbrowser
                    import os
                    webbrowser.open('file://' + os.path.abspath(html_file))

            elif query.startswith('/consult_entity'):
                entity = query[15:].strip()
                # Si aucun document n'est chargÃ©, l'explorateur sera vide.
                if not rag.custom_processor.fortran_processor.entity_manager.entities:
                    print("\nEntityManager est vide. Ajoutez des documents pour l'utiliser.")
                    return

                explorer = FortranEntityExplorer(rag.custom_processor.fortran_processor.entity_manager, rag.ontology_manager)

                report = await explorer.get_full_report(entity)
                # 4. Afficher le rapport de maniÃ¨re lisible
                if "error" in report:
                    print(f"\n--- ERREUR ---")
                    print(report["error"])
                else:
                    print(f"\n--- RAPPORT COMPLET POUR : {report['entity_name']} ---")

                    print("\n[ RÃ©sumÃ© ]")
                    for key, value in report['summary'].items():
                        print(f"  - {key.replace('_', ' ').capitalize()}: {value}")

                    print("\n[ Relations Sortantes (ce que cette entitÃ© utilise) ]")
                    for key, value in report['outgoing_relations'].items():
                        print(f"  - {key.replace('_', ' ').capitalize()}:")
                        if value:
                            for item in value:
                                print(f"    - {item}")
                        else:
                            print("    - (Aucun)")

                    print("\n[ Relations Entrantes (qui utilise cette entitÃ©) ]")
                    if report['incoming_relations']:
                        for caller in report['incoming_relations']:
                            print(f"  - {caller['name']} (type: {caller['type']}, file: {caller.get('file', 'N/A')})")
                    else:
                        print("  - (AppelÃ©e par personne)")

                    print("\n[ Contexte Global (oÃ¹ se situe cette entitÃ©) ]")
                    parent = report['global_context']['parent_entity']
                    if isinstance(parent, dict):
                        print(f"  - Parent: {parent['name']} (type: {parent['type']})")
                    else:
                        print(f"  - Parent: {parent}")

                    print("\n[ Contexte Local (ce que contient cette entitÃ©) ]")
                    children = report['local_context']['children_entities']
                    if children:
                        print("  - EntitÃ©s enfants:")
                        for child in children:
                            print(f"    - {child['name']} (type: {child['type']})")
                    else:
                        print("  - Pas d'entitÃ©s enfants.")

                    print("\n[ Concepts associÃ©s Ã  cette entitÃ© ]")
                    concepts = report['detected_concepts']
                    if concepts:
                        for concept in concepts:
                            print(f"  - {concept['label']} (confiance: {concept['confidence']})")

                    print("\n--- Code Source ---")
                    print(report['local_context']['source_code'])
                    print("--- FIN DU RAPPORT ---")

            elif query.startswith('/refresh'):
                scope = query[8:].strip()
                if scope == 'fortran' or not scope:
                    print("ðŸ”„ RÃ©indexation Fortran...")
                    await rag.refresh_fortran_index()
                    print("âœ… RÃ©indexation terminÃ©e")

            elif query.startswith('/agent '):
                # RÃ©cupÃ©rer la requÃªte initiale de l'utilisateur
                current_input = query[7:].strip()

                if current_input:
                    # DÃ©marrer une boucle de conversation qui continue tant que l'agent a besoin de clarifications.
                    while True:
                        print("ðŸ§  L'agent rÃ©flÃ©chit...")

                        # Appeler l'agent avec l'entrÃ©e actuelle.
                        # use_memory=True est CRUCIAL ici pour que l'agent se souvienne du contexte
                        # de sa propre question.
                        agent_response = await rag.agent_fortran.run(current_input, use_memory=True)

                        # VÃ©rifier si la rÃ©ponse de l'agent est une demande de clarification
                        if agent_response.startswith("CLARIFICATION_NEEDED:"):
                            # 1. Extraire la question de la chaÃ®ne de caractÃ¨res spÃ©ciale
                            question_from_agent = agent_response.replace("CLARIFICATION_NEEDED:", "").strip()

                            # 2. Afficher la question Ã  l'utilisateur de maniÃ¨re claire
                            print(f"\nâ“ L'agent a besoin d'une clarification pour continuer :")
                            print(f"   '{question_from_agent}'")

                            # 3. Demander une rÃ©ponse Ã  l'utilisateur via la console
                            user_clarification = input("\nVotre rÃ©ponse > ")

                            # 4. La rÃ©ponse de l'utilisateur devient la prochaine entrÃ©e pour l'agent
                            current_input = user_clarification

                            # La boucle `while` va maintenant se relancer avec cette nouvelle entrÃ©e.

                        else:
                            # Si la rÃ©ponse n'est PAS une clarification, c'est la rÃ©ponse finale.
                            print("\n--- RÃ‰PONSE FINALE DE L'AGENT ---")
                            print(agent_response)

                            # Sortir de la boucle de conversation.
                            break

            elif query.startswith("/agent_memory"):
                print("\n--- MÃ©moire de l'agent ---")
                print("\n" + rag.agent_fortran.get_memory_summary())

            elif query.startswith("/agent_clear"):
                rag.agent_fortran.clear_memory()
                print("ðŸ§  MÃ©moire de l'agent effacÃ©e.")

            # ==================== REQUÃŠTE NATURELLE ====================
            elif not query.startswith('/'):
                # RequÃªte naturelle - utiliser query() standard
                print(f"ðŸ’­ RequÃªte naturelle: {query}")
                await rag.ask(query)

            else:
                print("âŒ Commande inconnue. Tapez '/help' pour l'aide")

        except KeyboardInterrupt:
            print("\nðŸ‘‹ Au revoir !")
            break
        except Exception as e:
            print(f"âŒ Erreur: {e}")


async def display_intelligent_hierarchical_result(result: Dict[str, Any]):
    """Affiche les rÃ©sultats de la recherche hiÃ©rarchique intelligente"""

    print(f"\nðŸ¤– RÃ©ponse: {result.get('answer', 'Pas de rÃ©ponse')}")

    search_mode = result.get('search_mode', 'unknown')
    #print(f"\nðŸŽ¯ Mode de recherche utilisÃ©: {search_mode}")

    hierarchical_results = result.get('hierarchical_results', {})
    if hierarchical_results:
        print(f"\nðŸ“Š RÃ©sultats par niveau conceptuel:")

        for conceptual_level, level_data in hierarchical_results.items():
            display_name = level_data.get('display_name', conceptual_level)
            results = level_data.get('results', [])

            print(f"\nðŸ“š {display_name} ({len(results)} rÃ©sultats):")

            for i, res in enumerate(results[:3]):  # Top 3 par niveau
                if 'entity' in res:
                    # RÃ©sultat Fortran
                    entity = res['entity']
                    print(f"  {i + 1}. ðŸ”§ {entity.entity_name} ({entity.entity_type}) "
                          f"in {entity.filename} (sim: {res['similarity']:.2f})")
                else:
                    # RÃ©sultat texte
                    source_info = res.get('source_info', {})
                    title = source_info.get('section_title', 'Sans titre')
                    content_type = source_info.get('content_type', 'unknown')
                    icon = "ðŸ”§" if content_type == 'fortran' else "ðŸ“„"
                    print(f"  {i + 1}. {icon} {title} "
                          f"in {source_info.get('filename', 'Unknown')} (sim: {res['similarity']:.2f})")

    total_passages = result.get('total_passages', 0)
    conceptual_levels = result.get('conceptual_levels_found', [])

    print(f"\nðŸ“Š RÃ©sumÃ©: {total_passages} passages trouvÃ©s sur {len(conceptual_levels)} niveaux conceptuels")


async def display_full_report(report: Dict):
    # 4. Afficher le rapport de maniÃ¨re lisible
    if "error" in report:
        print(f"\n--- ERREUR ---")
        print(report["error"])
    else:
        print(f"\n--- RAPPORT COMPLET POUR : {report['entity_name']} ---")

        print("\n[ RÃ©sumÃ© ]")
        for key, value in report['summary'].items():
            print(f"  - {key.replace('_', ' ').capitalize()}: {value}")

        print("\n[ Relations Sortantes (ce que cette entitÃ© utilise) ]")
        for key, value in report['outgoing_relations'].items():
            print(f"  - {key.replace('_', ' ').capitalize()}:")
            if value:
                for item in value:
                    print(f"    - {item}")
            else:
                print("    - (Aucun)")

        print("\n[ Relations Entrantes (qui utilise cette entitÃ©) ]")
        if report['incoming_relations']:
            for caller in report['incoming_relations']:
                print(f"  - {caller['name']} (type: {caller['type']}, file: {caller.get('file', 'N/A')})")
        else:
            print("  - (AppelÃ©e par personne)")

        print("\n[ Contexte Global (oÃ¹ se situe cette entitÃ©) ]")
        parent = report['global_context']['parent_entity']
        if isinstance(parent, dict):
            print(f"  - Parent: {parent['name']} (type: {parent['type']})")
        else:
            print(f"  - Parent: {parent}")

        print("\n[ Contexte Local (ce que contient cette entitÃ©) ]")
        children = report['local_context']['children_entities']
        if children:
            print("  - EntitÃ©s enfants:")
            for child in children:
                print(f"    - {child['name']} (type: {child['type']})")
        else:
            print("  - Pas d'entitÃ©s enfants.")

        print("\n--- Code Source ---")
        print(report['local_context']['source_code'])
        print("--- FIN DU RAPPORT ---")


async def show_available_commands():
    """Affiche toutes les commandes disponibles utilisant les mÃ©thodes existantes"""
    print(f"""
ðŸ” RECHERCHE
   <question>                   RequÃªte naturelle directe
   /find <entitÃ©>               Recherche entitÃ©s Fortran (mÃ©thode: search_fortran_entities)
   /consult_entity              DonnÃ©es brut sur une entitÃ© fortran (rapport)
   /agent <question>            Deploit un agent de questionnement (utilise pour les grands rÃ©sumÃ©s et suivre une discussion)
   /agent_clear                 Efface la mÃ©moire de l'agent
   
ðŸ“Š RÃ‰SUMÃ‰S & STATISTIQUES
   /stats [detail]              Statistiques (get_statistics/get_fortran_stats)
   /stats entity                Stats EntityManager

ðŸ“ GESTION DOCUMENTS
   /list                        Lister documents (list_documents)

ðŸ”§ OUTILS & DIAGNOSTIC
   /diagnostic                  Diagnostic systÃ¨me (diagnose_fortran_entity_manager)
   /visualization               Graphique dÃ©pendances (generate_dependency_visualization)
   /refresh                     RÃ©indexer (refresh_fortran_index)

â“ AIDE
   /help                        Cette aide
   /quit                        Quitter
   
""")


# ==================== FONCTIONS D'AFFICHAGE ====================

async def display_query_result(result: Dict[str, Any]):
    """Affiche le rÃ©sultat d'une query() standard"""
    print(f"\nðŸ¤– RÃ©ponse: {result.get('answer', 'Pas de rÃ©ponse')}")

    sources = result.get('sources', [])
    if sources:
        print(f"\nðŸ“š Sources ({len(sources)}):")
        for source in sources:
            print(f"\n  ðŸ“„ {source['filename']} (lignes {source['start_line']}-{source['end_line']})")
            print(f"     Type: {source['entity_type']} - Nom: {source['entity_name']}")
            if source.get('detected_concepts'):
                print(f"     Concepts: {', '.join(source['detected_concepts'])}")
            print(f"     Score: {source['relevance_score']}")

async def display_hierarchical_result(result: Dict[str, Any]):
    """Affiche le rÃ©sultat d'une hierarchical_query()"""
    print(f"\nðŸ¤– RÃ©ponse: {result.get('answer', 'Pas de rÃ©ponse')}")

    hierarchical_results = result.get('hierarchical_results', {})
    if hierarchical_results:
        for level, results in hierarchical_results.items():
            print(f"\nðŸ“š Niveau {level} ({len(results)} rÃ©sultats):")
            for i, res in enumerate(results[:3]):
                chunk = res['chunk']
                title = chunk.get('metadata', {}).get('section_title', 'Sans titre')
                print(f"  {i + 1}. {title} (sim: {res['similarity']:.2f})")


async def display_fortran_entities(entities: List[Dict[str, Any]]):
    """Affiche les entitÃ©s Fortran trouvÃ©es"""
    if entities:
        print(f"ðŸ” {len(entities)} entitÃ©s Fortran trouvÃ©es:")
        for i, entity in enumerate(entities[:10], 1):
            confidence_icon = "ðŸŸ¢" if entity.get('confidence', 0) > 0.8 else "ðŸŸ¡" if entity.get('confidence',
                                                                                              0) > 0.5 else "ðŸ”´"
            print(f"  {i}. {confidence_icon} {entity['name']} ({entity['type']}) in {Path(entity['file']).name}")
            print(f"     Confidence: {entity.get('confidence', 0):.2f}, Match: {entity.get('match_type', 'unknown')}")
    else:
        print("âŒ Aucune entitÃ© Fortran trouvÃ©e")


async def display_document_list(docs: List[Dict[str, Any]]):
    """Affiche la liste des documents"""
    if not docs:
        print("ðŸ“ Aucun document chargÃ©")
        return

    print(f"ðŸ“ {len(docs)} documents chargÃ©s:")

    by_project = {}
    for doc in docs:
        project = doc.get('project', 'Unknown')
        if project not in by_project:
            by_project[project] = []
        by_project[project].append(doc)

    for project, project_docs in by_project.items():
        print(f"\n  ðŸ“‚ Projet: {project} ({len(project_docs)} docs)")
        for doc in project_docs:  # Top 5 par projet
            file_type = doc.get('file_type', 'unknown')
            chunks = doc.get('total_chunks', 0)
            print(f"    â€¢ {doc.get('filename', 'Unknown')} ({file_type}, {chunks} chunks)")


async def suggest_similar_entities(entity_name: str, rag):
    """SuggÃ¨re des entitÃ©s similaires en cas d'erreur"""
    try:
        # Utiliser search_fortran_entities avec terme partiel
        suggestions = await rag.search_fortran_entities(entity_name)
        if suggestions:
            print("ðŸ’¡ EntitÃ©s similaires trouvÃ©es:")
            for suggestion in suggestions[:5]:
                print(f"   - {suggestion['name']} ({suggestion['type']})")
    except:
        pass


# Fonctions d'affichage des contextes

async def _display_developer_context(context: Dict[str, Any]):
    """Affiche le contexte dÃ©veloppeur de maniÃ¨re formatÃ©e"""
    print("\n" + "=" * 60)
    print(f"ðŸ› ï¸  CONTEXTE DÃ‰VELOPPEUR - {context.get('entity', 'Unknown')}")
    print("=" * 60)

    # RÃ©sumÃ©
    summary = context.get('summary', {})
    entity_overview = summary.get('entity_overview', {})

    print(f"\nðŸ“‹ Vue d'ensemble:")
    print(f"   Type: {entity_overview.get('type', 'unknown')}")
    print(f"   Fichier: {entity_overview.get('file', 'unknown')}")
    print(f"   Signature: {entity_overview.get('signature', 'N/A')}")

    # ComplexitÃ©
    complexity = summary.get('complexity_analysis', {})
    if complexity:
        print(f"\nâš™ï¸  ComplexitÃ©: {complexity.get('level', 'unknown').upper()}")
        factors = complexity.get('complexity_factors', [])
        if factors:
            for factor in factors:
                print(f"   â€¢ {factor}")

    # Insights clÃ©s
    insights = context.get('key_insights', [])
    if insights:
        print(f"\nðŸ’¡ Insights clÃ©s:")
        for insight in insights[:5]:
            print(f"   â€¢ {insight}")

    # Recommandations
    recommendations = context.get('recommendations', [])
    if recommendations:
        print(f"\nðŸŽ¯ Recommandations:")
        for rec in recommendations[:3]:
            print(f"   â€¢ {rec}")

    # Contexte local
    local_ctx = context.get('contexts', {}).get('local', {})
    if local_ctx and 'error' not in local_ctx:
        deps = local_ctx.get('immediate_dependencies', [])
        calls = local_ctx.get('called_functions', [])

        if deps:
            print(f"\nðŸ“¦ DÃ©pendances ({len(deps)}):")
            for dep in deps[:5]:
                print(f"   â€¢ {dep.get('name', 'unknown')} ({dep.get('type', 'unknown')})")

        if calls:
            print(f"\nðŸ“ž Appels de fonctions ({len(calls)}):")
            for call in calls[:5]:
                status = "âœ…" if call.get('resolved', False) else "â“"
                print(f"   {status} {call.get('name', 'unknown')}")

    print(f"\nðŸ“Š Tokens utilisÃ©s: {context.get('total_tokens', 0)}")


async def _display_reviewer_context(context: Dict[str, Any]):
    """Affiche le contexte reviewer de maniÃ¨re formatÃ©e"""
    print("\n" + "=" * 60)
    print(f"ðŸ‘€ CONTEXTE REVIEWER - {context.get('entity', 'Unknown')}")
    print("=" * 60)

    # QualitÃ© et mÃ©triques
    summary = context.get('summary', {})
    quality = summary.get('quality_indicators', {})

    print(f"\nðŸŽ¯ Indicateurs de qualitÃ©:")
    print(f"   Richesse conceptuelle: {quality.get('conceptual_richness', 0)}")
    print(f"   ClartÃ© sÃ©mantique: {quality.get('semantic_clarity', 'unknown')}")
    print(f"   Patterns dÃ©tectÃ©s: {quality.get('pattern_detection', 0)}")

    # RÃ´le architectural
    arch_role = summary.get('architectural_role', '')
    if arch_role:
        print(f"\nðŸ—ï¸  RÃ´le architectural: {arch_role}")

    # Relations clÃ©s
    key_relations = summary.get('key_relationships', {})
    dependents = key_relations.get('dependents', [])
    affected_modules = key_relations.get('affected_modules', [])

    if dependents:
        print(f"\nðŸ”— EntitÃ©s dÃ©pendantes ({len(dependents)}):")
        for dep in dependents[:5]:
            print(f"   â€¢ {dep}")

    if affected_modules:
        print(f"\nðŸ“¦ Modules affectÃ©s ({len(affected_modules)}):")
        for mod in affected_modules[:3]:
            print(f"   â€¢ {mod}")

    # Insights spÃ©cifiques reviewer
    agent_insights = context.get('agent_specific_insights', [])
    if agent_insights:
        print(f"\nðŸ” Points de rÃ©vision:")
        for insight in agent_insights:
            print(f"   â€¢ {insight}")

    print(f"\nðŸ“Š Tokens utilisÃ©s: {context.get('total_tokens', 0)}")


async def _display_analyzer_context(context: Dict[str, Any]):
    """Affiche le contexte analyzer de maniÃ¨re formatÃ©e"""
    print("\n" + "=" * 60)
    print(f"ðŸ“Š CONTEXTE ANALYZER - {context.get('entity', 'Unknown')}")
    print("=" * 60)

    # Analyse d'impact depuis le contexte global
    global_ctx = context.get('contexts', {}).get('global', {})
    if global_ctx and 'error' not in global_ctx:
        impact = global_ctx.get('impact_analysis', {})

        if impact:
            print(f"\nâš ï¸  Analyse d'impact:")
            print(f"   Niveau de risque: {impact.get('risk_level', 'unknown').upper()}")
            print(f"   EntitÃ©s affectÃ©es: {impact.get('total_impact_entities', 0)}")
            print(f"   DÃ©pendants directs: {len(impact.get('direct_dependents', []))}")
            print(f"   Modules affectÃ©s: {len(impact.get('affected_modules', []))}")

            # Recommandations d'impact
            impact_recs = impact.get('recommendations', [])
            if impact_recs:
                print(f"\nðŸŽ¯ Recommandations d'impact:")
                for rec in impact_recs[:3]:
                    print(f"   â€¢ {rec}")

        # Graphe de dÃ©pendances
        dep_graph = global_ctx.get('dependency_graph', {})
        if dep_graph:
            nodes = dep_graph.get('nodes', {})
            edges = dep_graph.get('edges', [])
            print(f"\nðŸ•¸ï¸  Graphe de dÃ©pendances:")
            print(f"   NÅ“uds: {len(nodes)}")
            print(f"   Relations: {len(edges)}")

            # Montrer quelques relations clÃ©s
            for edge in edges[:5]:
                edge_type = edge.get('type', 'unknown')
                from_node = edge.get('from', '')
                to_node = edge.get('to', '')
                print(f"   {from_node} --{edge_type}--> {to_node}")

        # DÃ©pendances circulaires
        hierarchy = global_ctx.get('module_hierarchy', {})
        circular_deps = hierarchy.get('circular_dependencies', [])
        if circular_deps:
            print(f"\nðŸ”„ DÃ©pendances circulaires dÃ©tectÃ©es: {len(circular_deps)}")
            for cycle in circular_deps[:3]:
                print(f"   â€¢ {' â†’ '.join(cycle)}")

    print(f"\nðŸ“Š Tokens utilisÃ©s: {context.get('total_tokens', 0)}")


async def _display_semantic_context(context: Dict[str, Any]):
    """Affiche le contexte sÃ©mantique de maniÃ¨re formatÃ©e"""
    print("\n" + "=" * 60)
    print(f"ðŸ§  CONTEXTE SÃ‰MANTIQUE - {context.get('entity', 'Unknown')}")
    print("=" * 60)

    # Concepts principaux
    main_concepts = context.get('main_concepts', [])
    if main_concepts:
        print(f"\nðŸŽ¯ Concepts principaux:")
        for concept in main_concepts[:5]:
            label = concept.get('label', 'unknown')
            confidence = concept.get('confidence', 0)
            category = concept.get('category', 'unknown')
            print(f"   â€¢ {label} (conf: {confidence:.2f}, cat: {category})")

    # EntitÃ©s similaires
    similar_entities = context.get('similar_entities', [])
    if similar_entities:
        print(f"\nðŸ”— EntitÃ©s similaires:")
        for entity in similar_entities[:5]:
            name = entity.get('name', 'unknown')
            similarity = entity.get('similarity', 0)
            method = entity.get('method', 'unknown')
            reasons = entity.get('similarity_reasons', [])
            print(f"   â€¢ {name} (sim: {similarity:.2f}, mÃ©thode: {method})")
            if reasons:
                print(f"     Raisons: {', '.join(reasons[:2])}")

    # Patterns algorithmiques
    patterns = context.get('algorithmic_patterns', [])
    if patterns:
        print(f"\nðŸ”¬ Patterns algorithmiques:")
        for pattern in patterns[:3]:
            pattern_name = pattern.get('pattern', 'unknown')
            confidence = pattern.get('confidence', 0)
            print(f"   â€¢ {pattern_name} (conf: {confidence:.2f})")

    # Voisins sÃ©mantiques
    neighbors = context.get('semantic_neighbors', [])
    if neighbors:
        print(f"\nðŸŒ Voisins sÃ©mantiques:")
        for neighbor in neighbors[:5]:
            name = neighbor.get('name', 'unknown')
            score = neighbor.get('semantic_score', 0)
            shared_concepts = neighbor.get('shared_concepts', [])
            print(f"   â€¢ {name} (score: {score:.2f})")
            if shared_concepts:
                print(f"     Concepts partagÃ©s: {', '.join(shared_concepts[:2])}")

    # Relations cross-file
    cross_file = context.get('cross_file_relations', [])
    if cross_file:
        print(f"\nðŸ“ Relations entre fichiers:")
        for relation in cross_file[:3]:
            entity = relation.get('entity', 'unknown')
            file = Path(relation.get('file', '')).name
            strength = relation.get('relation_strength', 0)
            types = relation.get('relation_types', [])
            print(f"   â€¢ {entity} in {file} (force: {strength:.2f})")
            print(f"     Types: {', '.join(types)}")

    print(f"\nðŸ“Š Tokens utilisÃ©s: {context.get('total_tokens', 0)}")

if __name__ == "__main__":
    asyncio.run(example_usage())