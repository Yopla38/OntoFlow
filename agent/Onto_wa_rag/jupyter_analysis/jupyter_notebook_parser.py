# jupyter_notebook_parser.py
"""
------------------------------------------
Copyright: CEA Grenoble
Auteur: Yoann CURE (InspirÃ© par), Gemini (ImplÃ©mentation)
EntitÃ©: IRIG
AnnÃ©e: 2025
Description: Parseur de qualitÃ© production pour notebooks Jupyter (.ipynb)
             destinÃ© Ã  alimenter un systÃ¨me RAG.
------------------------------------------
"""

import json
import ast
import os
import logging
from typing import List, Dict, Any, Tuple, Optional

from ..fortran_analysis.core.entity_manager import UnifiedEntity


logger = logging.getLogger(__name__)


class CodeVisitor(ast.NodeVisitor):
    """
    Un NodeVisitor pour parcourir l'AST d'une cellule de code et extraire
    les fonctions, classes, imports et appels.
    Cette classe est conÃ§ue pour Ãªtre instanciÃ©e pour chaque portÃ©e d'analyse
    (cellule complÃ¨te, corps de fonction, etc.).
    """

    def __init__(self, filepath: str, parent_entity_name: str, source_code: str):
        self.entities: List[UnifiedEntity] = []
        self.dependencies: List[Dict[str, Any]] = []
        self.calls: List[Dict[str, Any]] = []
        self.filepath = filepath
        self.parent_stack = [parent_entity_name]
        self.source_lines = source_code.splitlines()

    def _get_full_source_segment(self, node: ast.AST) -> str:
        """Extrait le code source complet d'un nÅ“ud, y compris les dÃ©corateurs."""
        if hasattr(node, 'decorator_list') and node.decorator_list:
            first_node = node.decorator_list[0]
        else:
            first_node = node

        # ast.get_source_segment est la mÃ©thode la plus fiable
        try:
            return ast.get_source_segment(
                '\n'.join(self.source_lines),
                node,
                padded=True
            )
        except (TypeError, IndexError):
            # Fallback pour les cas oÃ¹ get_source_segment Ã©choue
            start = first_node.lineno - 1
            end = node.end_lineno
            return '\n'.join(self.source_lines[start:end])

    def _get_call_name(self, node: ast.Call) -> Optional[str]:
        """
        Extrait le nom qualifiÃ© complet d'un appel de fonction de maniÃ¨re rÃ©cursive.
        Exemples: 'print', 'np.array', 'pd.DataFrame.from_dict'
        """
        func = node.func
        parts = []
        while isinstance(func, ast.Attribute):
            parts.append(func.attr)
            func = func.value
        if isinstance(func, ast.Name):
            parts.append(func.id)
            return ".".join(reversed(parts))
        # GÃ¨re les appels chaÃ®nÃ©s comme plt.figure().add_subplot()
        if isinstance(func, ast.Call):
            return f"{self._get_call_name(func)}()"
        return None

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        self._process_function(node)

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> None:
        self._process_function(node)

    def _process_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef) -> None:
        parent = self.parent_stack[-1]
        full_source = self._get_full_source_segment(node)
        signature = full_source.split('\n')[0].strip()

        # Analyser le corps de la fonction pour trouver ses propres appels
        body_visitor = CodeVisitor(self.filepath, node.name, full_source)
        for sub_node in node.body:
            body_visitor.visit(sub_node)

        function_calls = body_visitor.calls

        entity = UnifiedEntity(
            entity_name=node.name,
            entity_type='async function' if isinstance(node, ast.AsyncFunctionDef) else 'function',
            start_line=node.lineno,
            end_line=node.end_lineno,
            filepath=self.filepath,
            parent_entity=parent,
            signature=signature,
            called_functions=function_calls,
            source_method='jupyter_ast',
            confidence=1.0
        )
        self.entities.append(entity)

        # Pas de self.generic_visit(node) ici pour Ã©viter de traiter
        # les appels et imports Ã  l'intÃ©rieur de la fonction au niveau supÃ©rieur.

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        parent = self.parent_stack[-1]
        full_source = self._get_full_source_segment(node)
        signature = full_source.split('\n')[0].strip()

        entity = UnifiedEntity(
            entity_name=node.name,
            entity_type='class',
            start_line=node.lineno,
            end_line=node.end_lineno,
            filepath=self.filepath,
            parent_entity=parent,
            signature=signature,
            source_method='jupyter_ast',
            confidence=1.0
        )
        self.entities.append(entity)

        # Visiter les enfants (mÃ©thodes, etc.) avec le nom de la classe comme parent
        self.parent_stack.append(node.name)
        self.generic_visit(node)
        self.parent_stack.pop()

    def visit_Import(self, node: ast.Import) -> None:
        for alias in node.names:
            dep_name = alias.asname or alias.name
            self.dependencies.append({'name': dep_name, 'line': node.lineno})

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        module = node.module or '.'
        for alias in node.names:
            full_name = f"{module}.{alias.name}"
            self.dependencies.append({'name': full_name, 'line': node.lineno})

    def visit_Call(self, node: ast.Call) -> None:
        call_name = self._get_call_name(node)
        if call_name:
            self.calls.append({'name': call_name, 'line': node.lineno})
        self.generic_visit(node)  # Continuer Ã  visiter les arguments de l'appel


class JupyterNotebookParser:
    """
    Parseur pour notebooks Jupyter qui identifie le rÃ©sumÃ© du notebook
    et l'injecte directement dans chaque entitÃ© crÃ©Ã©e.
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def parse_file(self, filepath: str) -> Tuple[List[UnifiedEntity], Dict[str, Any]]:
        """
        Analyse un notebook en deux passes internes :
        1. Parse toutes les cellules et identifie le rÃ©sumÃ©.
        2. Injecte le rÃ©sumÃ© dans toutes les entitÃ©s du notebook.
        """
        self.logger.info(f"ðŸš€ DÃ©marrage de l'analyse du notebook : {filepath}")
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                notebook_content = json.load(f)
        except Exception as e:
            self.logger.error(f"Erreur lors de la lecture/parsing de {filepath}: {e}")
            return [], {}

        # === PASSE 1 : Analyse et Identification du RÃ©sumÃ© ===
        all_entities = []
        summary_text_parts = []
        is_in_summary_section = True

        filename = os.path.basename(filepath)
        notebook_name = os.path.splitext(filename)[0]
        global_line_counter = 1

        # CrÃ©ation de l'entitÃ© notebook (sera enrichie plus tard)
        notebook_entity = UnifiedEntity(
            entity_name=notebook_name,
            entity_type="notebook",
            start_line=1,
            end_line=sum(len(c.get('source', [])) for c in notebook_content.get('cells', [])),
            filepath=filepath,
            filename=filename,
            source_code=json.dumps(notebook_content, indent=2)
        )
        all_entities.append(notebook_entity)

        for i, cell_data in enumerate(notebook_content.get('cells', [])):
            cell_entities, lines_in_cell = self._parse_cell(
                cell_data, i + 1, filepath, notebook_name, global_line_counter
            )

            if cell_entities:
                cell_root_entity = cell_entities[0]  # La premiÃ¨re entitÃ© est la cellule elle-mÃªme

                if is_in_summary_section:
                    if cell_root_entity.entity_type == 'markdown_cell':
                        # Cette cellule fait partie du rÃ©sumÃ©
                        cell_root_entity.entity_role = 'summary'
                        summary_text_parts.append(cell_root_entity.source_code)
                    elif cell_root_entity.entity_type == 'code_cell':
                        # Fin de la section rÃ©sumÃ©
                        is_in_summary_section = False

                all_entities.extend(cell_entities)

            global_line_counter += lines_in_cell

        # === PASSE 2 : Enrichissement des EntitÃ©s ===
        full_summary_text = "\n\n".join(summary_text_parts).strip()

        for entity in all_entities:
            entity.notebook_summary = full_summary_text

        # Liaison sÃ©mantique finale
        all_entities = self._link_markdown_to_code(all_entities)

        self.logger.info(f"âœ… Analyse de {filename} terminÃ©e. {len(all_entities)} entitÃ©s enrichies trouvÃ©es.")
        return all_entities, notebook_content

    def _parse_cell(self, cell_data: Dict, cell_number: int, filepath: str, parent_name: str, start_line_abs: int) -> \
    Tuple[List[UnifiedEntity], int]:
        cell_type = cell_data.get('cell_type')
        source_lines = cell_data.get('source', [])
        source_code = "".join(source_lines)
        num_lines = len(source_lines)

        if not source_code.strip():
            return [], num_lines

        cell_entity_name = f"{parent_name}_cell_{cell_number}"

        cell_entity = UnifiedEntity(
            entity_name=cell_entity_name,
            entity_type=f"{cell_type}_cell",
            start_line=start_line_abs,
            end_line=start_line_abs + num_lines - 1 if num_lines > 0 else start_line_abs,
            filepath=filepath,
            filename=os.path.basename(filepath),
            parent_entity=parent_name,
            source_code=source_code
        )

        entities = [cell_entity]

        if cell_type == 'code':
            try:
                tree = ast.parse(source_code)
                visitor = CodeVisitorWithOffset(filepath, cell_entity_name, source_code, start_line_abs)
                visitor.visit(tree)

                entities.extend(visitor.entities)
                cell_entity.dependencies = visitor.dependencies
                cell_entity.called_functions = visitor.calls
            except SyntaxError as e:
                self.logger.warning(
                    f"Erreur de syntaxe dans la cellule {cell_number} de {filepath} (ligne {e.lineno}). Analyse AST de la cellule ignorÃ©e.")

        return entities, num_lines

    def _link_markdown_to_code(self, entities: List[UnifiedEntity]) -> List[UnifiedEntity]:
        for i, entity in enumerate(entities):
            if entity.entity_type == 'markdown_cell' and entity.entity_role != 'summary':
                # On cherche la prochaine cellule de code
                for next_entity in entities[i + 1:]:
                    if next_entity.entity_type == 'code_cell':
                        entity.signature = f"Documentation for: {next_entity.entity_name}"
                        entity.entity_role = 'documentation'
                        break
        return entities


# visiteur qui gÃ¨re l'offset de ligne et le code source
class CodeVisitorWithOffset(ast.NodeVisitor):
    def __init__(self, filepath: str, parent_entity_name: str, source_code: str, line_offset: int):
        self.entities: List[UnifiedEntity] = []
        self.dependencies: List[Dict[str, Any]] = []
        self.calls: List[Dict[str, Any]] = []
        self.filepath = filepath
        self.parent_stack = [parent_entity_name]
        self.source_code = source_code
        self.line_offset = line_offset - 1  # L'offset est 0-indexed (start_line - 1)

    def _get_source_segment(self, node: ast.AST) -> str:
        return ast.get_source_segment(self.source_code, node) or ""

    def _get_call_name(self, node: ast.Call) -> Optional[str]:
        # ... (MÃªme logique que le prÃ©cÃ©dent) ...
        func = node.func
        parts = []
        while isinstance(func, ast.Attribute):
            parts.append(func.attr)
            func = func.value
        if isinstance(func, ast.Name):
            parts.append(func.id)
            return ".".join(reversed(parts))
        if isinstance(func, ast.Call):
            # Pour les appels chaÃ®nÃ©s, on reconstruit
            base = self._get_call_name(func)
            if base:
                return f"{base}()"  # ReprÃ©sentation simplifiÃ©e
        return None

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        parent = self.parent_stack[-1]
        signature = self._get_source_segment(node).split('\n')[0].strip()

        entity = UnifiedEntity(
            entity_name=node.name, entity_type='function',
            start_line=node.lineno + self.line_offset,
            end_line=node.end_lineno + self.line_offset,
            filepath=self.filepath, parent_entity=parent,
            signature=signature, source_code=self._get_source_segment(node)
        )
        # Visiter le corps pour trouver les appels INTERNES Ã  la fonction
        body_visitor = CodeVisitorWithOffset(self.filepath, node.name, self.source_code, self.line_offset)
        for sub_node in node.body:
            body_visitor.visit(sub_node)
        entity.called_functions = body_visitor.calls

        self.entities.append(entity)
        # NE PAS appeler generic_visit pour Ã©viter de compter les appels internes au niveau de la cellule

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        parent = self.parent_stack[-1]
        signature = self._get_source_segment(node).split('\n')[0].strip()

        entity = UnifiedEntity(
            entity_name=node.name, entity_type='class',
            start_line=node.lineno + self.line_offset,
            end_line=node.end_lineno + self.line_offset,
            filepath=self.filepath, parent_entity=parent,
            signature=signature, source_code=self._get_source_segment(node)
        )
        self.entities.append(entity)

        self.parent_stack.append(node.name)
        # On visite l'intÃ©rieur de la classe
        for sub_node in node.body:
            self.visit(sub_node)
        self.parent_stack.pop()

    def visit_Import(self, node: ast.Import) -> None:
        for alias in node.names:
            self.dependencies.append({'name': alias.name, 'line': node.lineno + self.line_offset})

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        module = node.module or '.'
        for alias in node.names:
            self.dependencies.append({'name': f"{module}.{alias.name}", 'line': node.lineno + self.line_offset})

    def visit_Call(self, node: ast.Call) -> None:
        call_name = self._get_call_name(node)
        if call_name:
            self.calls.append({'name': call_name, 'line': node.lineno + self.line_offset})

        # MODIFICATION pour la prÃ©cision des appels: ne pas visiter la fonction elle-mÃªme
        for arg in node.args:
            self.visit(arg)
        for kw in node.keywords:
            self.visit(kw.value)


class JupyterAnalysisEngine:
    """
    Interface unifiÃ©e pour l'analyse de notebooks Jupyter.
    GÃ¨re le parsing et un cache simple pour la performance.
    """

    def __init__(self):
        self.parser = JupyterNotebookParser()
        self._cache = {}

    def get_entities(self, filepath: str, use_cache: bool = True) -> List[UnifiedEntity]:
        """
        RÃ©cupÃ¨re toutes les entitÃ©s d'un notebook avec gestion du cache.
        """
        if use_cache and filepath in self._cache:
            return self._cache[filepath]

        entities, _ = self.parser.parse_file(filepath)

        if use_cache:
            self._cache[filepath] = entities

        return entities

    def analyze_file(self, filepath: str) -> Tuple[List[UnifiedEntity], Dict[str, Any]]:
        """
        Analyse un fichier notebook et retourne les entitÃ©s et le contenu brut.
        Cette mÃ©thode ne met pas en cache le contenu brut pour Ã©conomiser la mÃ©moire.
        """
        self.clear_cache()  # S'assurer que les donnÃ©es sont fraÃ®ches
        return self.parser.parse_file(filepath)

    def clear_cache(self):
        """Vide le cache d'analyse."""
        self._cache.clear()


# Fonction factory pour la cohÃ©rence avec votre projet existant
def get_jupyter_analyzer() -> JupyterAnalysisEngine:
    """
    Factory pour crÃ©er un analyseur de notebooks Jupyter.
    C'est le point d'entrÃ©e principal pour le systÃ¨me.
    """
    return JupyterAnalysisEngine()

# -------------------- CHUNKER -------------------------

def estimate_tokens(text: str, chars_per_token: int = 4) -> int:
    """
    Approxime le nombre de tokens en fonction du nombre de caractÃ¨res.
    - Par dÃ©faut: 1 token â‰ˆ 4 caractÃ¨res
    - Pour du texte mixte code/markdown, 1 token â‰ˆ 5 caractÃ¨res est parfois plus rÃ©aliste.
    """
    return max(1, len(text) // chars_per_token)


def chunk_notebook_entities(
    entities: List,
    target_size: int = 400,
    max_size: int = 800,
    chars_per_token: int = 4  # 4 for english, 5 for french
) -> List[Dict]:
    """
    Construit des chunks optimisÃ©s Ã  partir des entitÃ©s d'un notebook.
    Approximation des tokens par longueur des caractÃ¨res.
    """

    chunks = []
    current_chunk = []
    current_tokens = 0

    for entity in entities:
        if entity.entity_type == "notebook":
            continue

        text = entity.source_code or ""
        if not text.strip():
            continue

        tokens = estimate_tokens(text, chars_per_token)

        # Cellule Ã©norme â†’ chunk isolÃ©
        if tokens > max_size:
            if current_chunk:
                chunks.append({
                    "content": "\n\n".join(current_chunk),
                    "tokens": current_tokens
                })
                current_chunk, current_tokens = [], 0

            chunks.append({"content": text, "tokens": tokens})
            continue

        # Sinon on essaie dâ€™ajouter au chunk courant
        if current_tokens + tokens <= target_size:
            current_chunk.append(text)
            current_tokens += tokens
        else:
            if current_chunk:
                chunks.append({
                    "content": "\n\n".join(current_chunk),
                    "tokens": current_tokens
                })
            current_chunk = [text]
            current_tokens = tokens

    if current_chunk:
        chunks.append({
            "content": "\n\n".join(current_chunk),
            "tokens": current_tokens
        })

    return chunks


if __name__ == "__main__":


    # Configurez un logger basique pour voir les messages
    logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')

    # CrÃ©ez un notebook de test nommÃ© 'test_notebook.ipynb'
    # avec des cellules de code (fonctions, classes, imports) et de markdown.

    analyzer = get_jupyter_analyzer()
    filepath = '/home/yopla/PycharmProjects/llm-hackathon-2025/2-aiengine/OntoFlow/agent/agent/Onto_wa_rag/jupyter_analysis/test.ipynb'

    # Obtenir toutes les entitÃ©s structurÃ©es
    entities, raw_content = analyzer.analyze_file(filepath)

    print(f"\n--- Analyse de '{filepath}' ---")
    print(f"Nombre total d'entitÃ©s trouvÃ©es : {len(entities)}")

    for entity in entities:
        print("\n------------------------------")
        print(f"Nom      : {entity.entity_name}")
        print(f"Type     : {entity.entity_type}")
        print(f"Parent   : {entity.parent_entity}")
        print(f"Lignes   : {entity.start_line} Ã  {entity.end_line}")
        if entity.signature:
            print(f"Signature: {entity.signature}")
        if entity.dependencies:
            deps = [d['name'] for d in entity.dependencies]
            print(f"DÃ©pendances: {deps}")
        if entity.called_functions:
            calls = [c['name'] for c in entity.called_functions]
            print(f"Appels   : {calls}")
        if entity.source_code:
            print(f"Source   : {entity.source_code}")

    chunk = chunk_notebook_entities(entities)
    print(chunk[0])
